# JavaScript 数据结构与算法

## 一、栈（stack）

栈是一种**受限的线性表，后进先出（LIFO：Last In First Out）**

- 后进入的元素，第一个弹出栈空间。类似于自动餐托盘，最后放上的托盘，往往先把拿出去使用。
- 其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。
- 向一个栈插入新元素又称作进栈、入栈或压栈，它是把新元素放到栈顶元素的上面，使之成为新的栈顶元素；
- 从一个栈删除元素又称作出栈或退栈，它是把栈顶元素删除掉，使其相邻的元素成为新的栈顶元素。

### 栈结构示意图

![img](https://img-blog.csdnimg.cn/20200927203524711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**程序中用栈实现的**

函数调用栈：A 调用 B，B 调用 C，执行的过程中，栈底->A->B->C->栈顶，C 执行完，弹出栈，B、A 依次弹出。

### 栈结构实现

**实现栈结构有两种比较常见的方式：**

- 基于数组实现
- 基于链表实现

#### 常见的操作

- `push()`：添加一个新元素到栈顶位置。
- `pop()`：移除栈顶的元素，同时返回被移除的元素。
- `peek()`：返回栈顶的元素，不对栈做任何修改（该方法不会移除栈顶的元素，仅仅返回它）。
- `isEmpty()`：如果栈里没有任何元素就返回 `true`，否则返回 `false`。
- `size()`：返回栈里的元素个数。这个方法和数组的 `length` 属性类似。
- `toString()`：将栈结构的内容以字符串的形式返回。

## 二、队列（Queue）

队列是一种**运算受限的线性表，先进先出（FIFO：First In First Out）**

**受限之处**

- 只允许在表的前端（front）进行删除操作
- 只允许在表的后端（rear）进行插入操作

### 队列图解

![img](https://img-blog.csdnimg.cn/20200927203635741.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**生活中类似队列结构的场景**

- 排队，比如在电影院，商场，甚至是厕所排队
- 优先排队的人，优先处理 (买票、结账、WC)。

**队列在程序中的应用**

- 打印队列：计算机打印多个文件的时候，需要排队打印。
- 线程队列：当开启多线程时，当新开启的线程所需的资源不足时就先放入线程队列，等待 CPU 处理。（类似 JS 中的任务队列）

### 队列的实现

**实现队列有两种比较常见的方式：**

- 基于数组实现
- 基于链表实现

#### 常见的操作

- `enqueue(element)`：向队列尾部添加一个（或多个）新的项。
- `dequeue()`：移除队列的第一（即排在队列最前面的）项，并返回被移除的元素。
- `front()`：返回队列中第一个元素——最先被添加，也将是最先被移除的元素。队列不做任何变动（不移除元素，只返回元素信息——与 `Stack` 类的 `peek` 方法非常类似）。
- `isEmpty()`：如果队列中不包含任何元素，返回`true`，否则返回`false`。
- `size()`：返回队列包含的元素个数，与数组的`length`属性类似。

## 三、优先级队列（PriorityQueue）

上面，是一种普通的队列。 队列中元素的处理顺序和插入的顺序密切相关。但是，还有一种比较常见的场景是和插入顺序无关，而和元素本身的优先级有关系的队列。

这种队列就是优先级队列。

**生活中类似优先队列的场景**

- 优先排队的人，优先处理（买票、结账、WC）
- 排队中，有紧急情况（特殊情况）的人可优先处理

计算机中，我们也可以通过优先级队列来重新排序队列中任务的顺序

- 比如每个线程处理的任务重要性不同，我们可以通过优先级的大小，来决定该线程在队列中被处理的次序

**优先级队列主要考虑的问题**

- 每个元素不再只是一个数据，还包含优先级
- 在添加元素过程中，根据优先级放入到正确位置

### 优先级队列的实现

实现优先级队列相对队列主要有两方面需要考虑

1. 将元素和优先级封装在一起（可以封装一个新的类）

- 封装了一个 QueueElement，将 element 和 priority 封装在一起

1. 添加元素时，将当前的优先级和队列中已经存在的元素优先级进行比较，以获得自己正确的位置

   > 在插入新的元素时，有如下情况下考虑
   >
   > - 根据新的元素先创建一个新的 QueueElement 对象
   > - 如果元素是第一个被加进来的，那么不需要考虑太多，直接加入数组中即可
   > - 如果是后面加进来的元素，需要和前面加进来的元素依次对比优先级
   > - 一旦优先级，大于某个元素，就将该元素插入到元素这个元素的位置，其他元素会依次向后移动
   > - 如果遍历了所有的元素，没有找到某个元素比这个新元素的优先级低，直接放在最后即可

### 数组、栈和队列图解

![img](https://img-blog.csdnimg.cn/20200927204115376.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

## 四、链表（LinkedList）

### 4.1 链表和数组

链表和数组一样，可以用于存储一系列的元素，但是链表和数组的实现机制完全不同。

#### 数组

- 存储多个元素，数组（或称为列表）可能是最常用的数据结构
- 几乎每一种编程语言都有默认实现数组结构，提供了一个便利的 `[]` 语法来访问数组元素
- 数组缺点：
  - 数组的创建需要申请一段**连续的内存空间**（一整块内存），并且大小是固定的，当前数组**不能满足容量需求时，需要扩容** (一般情况下是申请一个更大的数组，比如 2 倍，然后将原数组中的元素复制过去)
  - 在数组开头或中间位置插入数据的成本很高，需要进行大量元素的位移

#### 链表

- 存储多个元素，另外一个选择就是使用**链表**
- 不同于数组，链表中的元素在内存中**不必是连续的空间**
- 链表的每个元素由一个**存储元素本身的节点**和一个**指向下一个元素的引用**(有些语言称为指针)组成
- 链表优点：
  - 内存空间不必是连续的，可以充分利用计算机的内存，实现灵活的**内存动态管理**
  - 链表不必在创建时就**确定大小**，并且大小可以**无限延伸**下去
  - 链表在**插入和删除**数据时，**时间复杂度**可以达到 O(1)，相对数组效率高很多。
- 链表缺点：
  - 访问任何一个位置的元素时，需要从头开始访问（无法跳过第一个元素访问任何一个元素）
  - 无法通过下标值直接访问元素，需要从头开始一个个访问，直到找到对应的元素。虽然可以轻松地到达下一个节点，但是回到前一个节点是很难的。

### 4.2 单向链表

单向链表类似于火车，有一个火车头，火车头会连接一个节点，节点上有乘客，并且这个节点会连接下一个节点，以此类推。

**单向链表的图解**

![img](https://img-blog.csdnimg.cn/20200927204313172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 单向链表的实现

##### 常见的操作

append(element)：向列表尾部添加一个新的项

insert(position, element)：向链表的特定位置插入一个新的项

getElement(position)：获取对应位置的元素

indexOf(element)：返回元素在列表中的索引，如果没有该元素则返回 -1

update(position, element)：修改某个位置的元素

removeAt(position)：从列表的特定位置移除一项，并返回删除的那个节点

remove(element)：从列表移除一项，并返回删除的那个节点

isEmpty()：如果链表中不包含任何元素返回 true，如果链表长度大于 0 返回 false

size()：返回链表包含的元素个数，与数组的 length 属性类似

### 4.3 双向链表

#### 单向链表

- 只能从头遍历到尾或者从尾遍历到头（一般从头到尾）。
- 链表相连的过程是单向的，实现原理是上一个节点中有指向下一个节点的引用。
- 单向链表有一个比较明显的缺点：可以轻松到达下一个节点，但回到前一个节点很难，在实际开发中, 经常会遇到需要回到上一个节点的情况。

#### 双向链表

- 既可以从头遍历到尾，也可以从尾遍历到头。
- 链表相连的过程是双向的。实现原理是**一个节点既有向前连接的引用，也有一个向后连接的引用**。
- 双向链表可以有效的解决单向链表存在的问题。
- 双向链表缺点：
  - 每次在插入或删除某个节点时，都需要处理四个引用，而不是两个，实现起来会困难些。
  - 相对于单向链表，所占内存空间更大一些。
  - 但是，相对于双向链表的便利性而言，这些缺点微不足道。

**双向链表的图解**

![img](https://img-blog.csdnimg.cn/20200927203833989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

- 双向链表不仅有 head 指针指向第一个节点，而且有 tail 指针指向最后一个节点。
- 每一个节点由三部分组成：item 储存数据、prev 指向前一个节点、next 指向后一个节点。
- 双向链表的第一个节点的 prev 指向 null。
- 双向链表的最后一个节点的 next 指向 null。

#### 双向链表的实现

![img](https://img-blog.csdnimg.cn/20200927210020485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 双向链表常见的操作

- `append(element)` 向链表尾部追加一个新元素。
- `insert(position, element)` 向链表的指定位置插入一个新元素。
- `getElement(position)` 获取指定位置的元素。
- `indexOf(element)` 返回元素在链表中的索引。如果链表中没有该元素就返回 -1。
- `update(position, element)` 修改指定位置上的元素。
- `removeAt(position)` 从链表中的删除指定位置的元素。
- `remove(element)` 从链表删除指定的元素。
- `isEmpty()` 如果链表中不包含任何元素，返回 trun，如果链表长度大于 0 则返回 false。
- `size()` 返回链表包含的元素个数，与数组的 length 属性类似。
- `toString()` 由于链表项使用了 Node 类，就需要重写继承自 JavaScript 对象默认的 toString 方法，让其只输出元素的值。
- `forwardString()` 返回正向遍历节点字符串形式。
- `backwordString()` 返回反向遍历的节点的字符串形式。

## 五、集合（Set）

**集合结构**，通常是由一组**无序的**，**不能重复的**元素构成

- 和在数学中的名词比较相似，但是数学中的集合范围更大一些，也允许集合中的元素重复
- 在计算机中，集合通常表示的结构中元素是不允许重复的

其实集合你可以将它可以看成一种**特殊的数组**

- 特殊之处在于里面的元素**没有顺序**，**也不能重复**
- 没有顺序意味着**不能通过下标值进行访问**，不能重复意味着**相同的对象在集合中只会存在一份**

### 集合的实现

> 数组。集合、字典是几乎每种编程语言都会默认提供的数据结构。
>
> JS 中默认提供了数组，ES6 中增加了集合（Set）和字典（Map），所以其实我们可以不封装，直接使用。
>
> 但是这里，为了明确集合的内部实现机制，我们这里还是自己来封装一下 Set 类。
>
> 集合比较常见的实现方式是哈希表，在这里先通过对象实现。

#### 集合常见的操作

- `add(value)` 向集合添加一个新的项。
- `remove(value)` 从集合移除一个值。
- `has(value)` 如果值在集合中，返回 true，否则返回 false。
- `clear()` 移除集合中的所有项。
- `size()` 返回集合所包含元素的数量。与数组的 length 属性类似。
- `values()` 返回一个包含集合中所有值的数组。
- 还有其他的方法，用的不多，这里不做封装。

#### 集合间的操作

- `union()` 并集：对于给定的两个集合，返回一个包含两个集合中所有元素的新集合。
- `intersection()` 交集：对于给定的两个集合，返回一个包含两个集合中共有元素的新集合。
- 差集：对于给定的两个集合，返回一个包含所有存在于第一个集合且不存在于第二个集合的元素的新集合。
- 子集：验证一个给定集合是否是另一个集合的子集。

![img](https://img-blog.csdnimg.cn/20200927204638647.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

## 六、字典/映射（Map）

字典（或者称为映射）存储的是**键值对**，主要特点是——**对应**的关系。

比如保存一个人的信息：

- 使用数组的方式：[18, 'wy', 160]，可以通过下标值取出信息
- 使用字典的方式：{'age': 18, 'name': 'wy', 'height': 160}，可以通过 key 取出 value

另外，字典中的 **key 是不可以重复的、无序的，而 value 可以重复**

**字典的映射关系**

有些编程语言中称这种映射关系为**字典**，因为它确定和生活中的字典比较相似，比如 Python 中的 dict、Swift 中的 Dictionary

有些编程语言中称为这种映射关系为 **Map**（注意 Map 在这里不是地图，而是映射的意思），比如 Java 中的 HashMap&TreeMap 等

**字典和数组**

- 字典和数组对比的话, 字典可以非常方便的通过 key 来搜索对应的 value，key 可以包含特殊含义，也更容易被人们记住。而数组是通过下标。并且字典的 key 不允许重复。

**字典和对象**

- 很多编程语言（比如 Java）中对字典和对象区分比较明显，对象通常是一种在编译期就确定下来的结构，不可以动态的添加或者删除属性。而字典通常会使用类似于哈希表的数据结构去实现一种可以动态的添加数据的结构
- 但是在 JavaScript 中，似乎对象本身就是一种字典。所以在早期的 JS 中，没有字典这种数据类型，因为你完全可以使用对象去代替
- 但是这里我们还是按照其他语言经常使用字典的方式去封装一个字典类型，方便我们按照其他语言的方式去使用字典（虽然本质上它内部还是用了对象）

### 字典的实现

#### 字典常见的操作

- `set(key,value)` 向字典中添加新元素。
- `remove(key)` 通过使用键值来从字典中移除键值对应的数据值。
- `has(key)` 如果某个键值存在于这个字典中，则返回 `true`，反之则返回 `false`。
- `get(key)` 通过键值查找特定的数值并返回。
- `clear()` 将这个字典中的所有元素全部删除。
- `size()` 返回字典所包含元素的数量。与数组的 `length` 属性类似。
- `keys()` 将字典所包含的所有键名以数组形式返回。
- `values()` 将字典所包含的所有数值以数组形式返回。

## 七、哈希表（HashTable）

哈希表是一种非常重要的数据结构，几乎所有的编程语言都**直接或间接**应用这种数据结构。

哈希表通常是基于**数组**实现的，但是相对于数组，它存在很多**优势**：

- 哈希表可以提供非常快速的**插入-删除-查找操作**
- 无论多少数据，插入和删除值都只需要接近常量的时间，即 **O(1)** 的时间复杂度。实际上，只需要**几个机器指令**即可完成
- 哈希表的速度**比树还要快**，基本可以瞬间查找到想要的元素
- 哈希表相对于树来说编码要简单得多

哈希表同样存在**不足**之处：

- 哈希表中的数据是**没有顺序**的，所以不能以一种固定的方式（比如从小到大）来遍历其中的元素
- 通常情况下，哈希表中的 key 是**不允许重复**的，不能放置相同的 key，用于保存不同的元素

**哈希表到底是什么？**

- 哈希表并不好理解，不像数组、链表和树等可通过图形的形式表示其结构和原理
- **哈希表的结构就是数组**，但它神奇之处在于**对下标值的一种变换**，这种变换我们可以称之为**哈希函数**，通过哈希函数可以获取 **HashCode**

**通过以下案例了解哈希表**

1. 公司想要存储 1000 个人的信息：每个工号对应一个员工的信息。若使用数组，增删数据时比较麻烦；使用链表，获取数据时比较麻烦。有没有一种数据结构，能把某一员工的姓名转换为它对应的工号。再根据工号查找该员工的完整信息呢？此时就可以使用哈希表的哈希函数来实现。
2. 存储联系人和对应的电话号码：当要查找张三的号码时，若使用数组，由于不知道存储张三数据对象的下标值，所以查找起来十分麻烦，使用链表时也同样麻烦。而使用哈希表就能通过哈希函数把张三这个名称转换为它对应的下标值，再通过下标值查找效率就非常高了。
3. 存储 50000 个单词：同样，不能用线性查找的结构：数组、链表，那样需要一个一个遍历比较，效率非常低。而哈希表将单词转成数组的下标，那么我们查找某个单词，直接按照下标值一步即可访问到想要的元素。

也就是说：哈希表最后还是基于数组来实现的，只不过哈希表能够通过哈希函数把字符串转化为对应的下标值，建立字符串和下标值的映射关系。

### 7.1 认识哈希化

为了把**字符串转化为对应的下标值**，即**字母/文字**转**数字**，需要有一套编码系统

- 计算机中有很多的编码方案是用数字代替单词的字符，即字符编码
- 比如 ASCII 编码：a 是 97，b 是 98...
- 我们也可以创建自己的一套编码系统：比如 a 为 1，b 为 2，c 为 3，以此类推 z 为 26，空格为 27（不考虑大写情况）。

有了编码系统后，将字母转化为数字也有很多种方案：

- 方案一：**数字相加**

例如 cats 转化为数字：`3 + 1 + 20 + 19 = 43`，那么就把 43 作为 cats 单词的下标值储存在数组中；

但是这种方式会存在这样的问题：很多的单词按照该方式转化为数字后都是 43，比如 was/tin/give 等。而在数组中**一个下标值只能储存一个数据**，存入后来的数据，必然会造成**数据的覆盖**，所以该方式**不合理**。

- 方案二：**幂的连乘**

我们平时使用的大于 10 的数字，就是用幂的连乘来表示它的唯一性的。
比如： `6543 = 6 * 10^3 + 5 * 10^2 + 4 * 10 + 3`；这样单词也可以用该种方式来表示：`cats = 3 * 27^3 + 1 * 27^2 + 20 * 27 + 17 = 60337`。

虽然该方式基本可以保证字符的**唯一性**，但是如果是较长的字符（如 zzzzzzzzzz）得到的数字就非常大，此时要求很大容量的数组，然而其中却有许多下标值指向的是无效的数据（比如不存在 zxcvvv 这样的单词），创建这么大的数组是没有意义的。

**两种方案总结：**

- 第一种方案（把数字相加求和）产生的**数组下标太少**。
- 第二种方案（与 27 的幂相乘求和）产生的**数组下标又太多**。

现在需要一种**压缩方法**，把幂的连乘方案系统中得到的**巨大整数范围压缩到可接受的数组范围中**。如果只有 50000 个单词，在实际情况中就需要更大的空间来存储（比如两倍的大小：100000），因为我们不能保证单词会映射到每一个位置。

可以通过**取余**操作来实现。

- 比如，假设把从 0 ~ 199 的数字（largeNumber）压缩为从 0 到 9 的数字（smallRange），下标值 `index = largeNumber % smallRange`。
- 当一个数被 10 整除时，其余数一定在 0 ~ 9 之间
- 当然，这中间还是会有重复，但是重复的数量明显变小了（真的发生重复了，也可以通过其他方式解决），因为我们的数组是 100000，而只有 50000 个单词。

### 7.2 哈希表的一些概念

**哈希化**

将大数字 --> 数组范围内下标的小数字的过程，称之为哈希化

**哈希函数**

我们通常会将单词 --> 大数字，把大数字 --> 小数字（即哈希化）的代码实现放在一个函数中，该函数就称为哈希函数

**哈希表**

对最终数据插入的数组进行整个结构的封装，得到的就是哈希表

### 7.3 什么是冲突

尽管 50000 个单词， 使用了 100000 个位置来存储，并且通过一种相对比较好的哈希函数来完成，但是依然有可能会发生冲突。

- 比如 melioration 这个单词，通过哈希函数得到它数组的下标值后，发现那个位置上已经存在一个单词 demystify

这种情况我们称为**冲突**，冲突**不可避免**，我们只能**解决冲突**。

解决冲突常见的两种方案：链地址法（拉链法）和开放地址法。

#### 7.3.1 链地址法（拉链法）

![img](https://img-blog.csdnimg.cn/20200927204638571.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

如图所示，每一个数字都对 10 进行取余操作，则余数的范围 0~9 作为数组的下标值。并且，数组每一个下标值对应的位置存储的不再是单个数字了，而是存储一个由相同下标的数字组成的数组或链表。

这样可以根据下标值获取到整个数组或链表，之后继续在数组或链表中查找就可以了。而且，产生冲突的元素一般不会太多。

总结：链地址法解决冲突的办法是每个数组单元中存储的不再是单个数据，而是一条链条，这条链条常使用的数据结构为数组或链表，两种数据结构查找的效率相当（因为链条的元素一般不会太多）。

#### 7.3.2 开放地址法

开放地址法的主要工作方式是寻找空白的单元格来放置冲突的数据项。

![img](https://img-blog.csdnimg.cn/20200927204638587.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

根据探测空白单元格位置方式的不同，可分为三种方法：

- 线性探测
- 二次探测
- 再哈希法

##### 7.3.2.1 线性探测

- 当插入 13 时：

经过哈希化（对 10 取余）之后得到的下标值 index=3，但是该位置已经放置了数据 33。而线性探测就是从 index 位置+1 开始向后一个一个来查找合适的位置来放置 13，所谓合适的位置指的是空的位置，如上图中 index=4 的位置就是合适的位置。

- 当查询 13 时：
  - 首先 13 经过哈希化得到 index=3，如果 index=3 的位置存放的数据与需要查询的数据 13 相同，就直接返回；
    不相同时，则线性查找，从 index+1 位置开始一个一个位置地查找数据 13。
  - 查询过程中不会遍历整个哈希表，只要查询到空位置，就停止，因为插入 13 时不会跳过空位置去插入其他位置。
- 当删除 13 时：
  - 删除操作和上述两种情况类似，但需要注意的是，删除一个数据项时，不能将该位置下标的内容设置为 null，否则会影响到之后其他的查询操作，因为一遇到为 null 的位置就会停止查找。
  - 通常删除一个位置的数据项时，我们可以将它进行特殊处理（比如设置为-1），这样在查找时遇到-1 就知道要继续查找。

线性探测存在的问题：

- 线性探测存在一个比较严重的问题，就是聚集。
- 如哈希表中还没插入任何元素时，插入 23、24、25、26、27，这就意味着下标值为 3、4、5、6、7 的位置都放置了数据，这种一连串填充单元就称为聚集。
- 聚集会影响哈希表的性能，无论是插入/查询/删除都会影响。
- 比如插入 13 时就会发现，连续的单元 3~7 都不允许插入数据，并且在插入的过程中需要经历多次这种情况。二次探测法可以解决该问题。

![img](https://img-blog.csdnimg.cn/20200927210518336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 7.3.2.2 二次探测

上文所说的线性探测存在问题：

- 如果之前的数据是连续插入的，那么新插入的一个数据可能需要探测很长的距离；

  二次探测是在线性探测的基础上进行了优化：

- 线性探测：我们可以看成是步长为 1 的探测，比如从下表值 x 开始，那么线性探测就是按照下标值：x+1、x+2、x+3 等依次探测；

- 二次探测：对步长进行了优化，比如从下标值 x 开始探测：x+1^2、x+2^2、x+3^2 。这样一次性探测比较长的距离，避免了数据聚集带来的影响。

- 二次探测存在的问题：

  当插入数据分布性较大的一组数据时，比如：13-163-63-3-213，这种情况会造成步长不一的一种聚集（虽然这种情况出现的概率较线性探测的聚集要小），同样会影响性能。

##### 7.3.2.3 再哈希法

在开放地址法中寻找空白单元格的最好的解决方式为再哈希化。

- 二次探测的步长是固定的：1，4，9，16 依次类推。
- 现在需要一种方法：产生一种依赖关键字(数据)的探测序列，而不是每个关键字探测步长都一样。
- 这样，不同的关键字即使映射到相同的数组下标，也可以使用不同的探测序列。
- 再哈希法的做法为：把关键字用另一个哈希函数，再做一次哈希化，用这次哈希化的结果作为该关键字的步长。

第二次哈希化需要满足以下两点：

- 和第一个哈希函数不同，不然哈希化后的结果仍是原来位置；
- 不能输出为 0，否则每次探测都是原地踏步的死循环；

优秀的哈希函数：

- stepSize = constant - （key % constant）；
- 其中 constant 是质数，且小于数组的容量；
- 例如：stepSize = 5 - （key % 5），满足需求，并且结果不可能为 0；

#### 7.3.3 哈希化的效率

哈希表中执行插入和搜索操作效率是非常高的。

- 如果**没有发生冲突**，那么效率就会更高；
- 如果**发生冲突**，存取时间就依赖后来的探测长度；
- 平均探测长度以及平均存取时间，取决于**填装因子**，随着填装因子变大，探测长度会越来越长。

##### 装填因子

- 装填因子表示当前哈希表中**已经包含的数据项**和**整个哈希表长度**的**比值**；
- **装填因子 = 总数据项 / 哈希表长度**；
- **开放地址法的装填因子最大为 1**，因为只有空白的单元才能放入元素；
- **链地址法的装填因子可以大于 1**，因为只要愿意，拉链法可以无限延伸下去；

##### 不同探测方式性能的比较

- 线性探测

  可以看到，随着装填因子的增大，平均探测长度呈指数形式增长，性能较差。实际情况中，最好的装填因子取决于存储效率和速度之间的平衡，随着装填因子变小，存储效率下降，而速度上升。

![img](https://img-blog.csdnimg.cn/20200927210528795.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

- 二次探测和再哈希化的性能

  二次探测和再哈希法性能相当，它们的性能比线性探测略好。由下图可知，随着装填因子的变大，平均探测长度呈指数形式增长，需要探测的次数也呈指数形式增长，性能不高。

![img](https://img-blog.csdnimg.cn/20200927210535380.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

- 链地址法的性能

  可以看到随着装填因子的增加，平均探测长度呈线性增长，较为平缓。**在开发中使用链地址法较多**，比如 Java 中的 HashMap 中使用的就是链地址法。

![img](https://img-blog.csdnimg.cn/20200927210541773.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 7.4 哈希函数

哈希表的优势在于它的速度，所以哈希函数不能采用消耗性能较高的复杂算法。提高速度的一个方法是在哈希函数中尽量减少乘法和除法。

性能高的哈希函数应具备以下两个优点：

- 快速的计算：快速通过计算来获取到对应的 hashCode
- 均匀的分布：尽可能将元素映射到不同的位置，让元素在哈希表中均匀的分布

#### 快速计算：霍纳法则

在前面，计算哈希值的时候使用的方式是：

- cats = 3 _ 27^3 + 1 _ 27^2 + 20 * 27 + 17 = 60337
- 这种方式是直观的计算结果，那么这种计算方式会进行几次乘法几次加法呢？把这个表达式抽象为多项式：

![img](https://img-blog.csdnimg.cn/20200927211440191.png#pic_center)

现在问题就变成了多项式有多少次乘法和加法：

- 乘法次数：n + (n - 1) + ... + 1 = n(n + 1)/2 次
- 加法次数：n 次
- O(N^2)

通过霍纳法则进行多项式的优化，通过如下变换我们可以得到一种**快得多**的算法：

![img](https://img-blog.csdnimg.cn/202009272114461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

求多项式的值时，首先计算最内层括号内一次多项式的值，然后由内向外逐层计算一次多项式的值。这种算法把求 n 次多项式 f(x)的值就转化为求 n 个一次多项式的值。

变换之后：

- 乘法次数：n 次；
- 加法次数：n 次；

如果使用大 O 表示时间复杂度的话，直接从变换前的 O(N^2) 降到了 O(N)。

#### 均匀分布

在设计哈希表时，我们已经有办法处理**映射到相同下标值**的情况：链地址法或者开放地址法。但是，为了提供效率，最好的情况还是让数据在哈希表中**均匀分布**。因此，我们需要**在使用常量的地方**，尽量使用**质数**。比如：哈希表的长度、N 次幂的底数等。

> 哈希表的长度最好使用质数
>
> 1.再哈希法中质数的重要性：
>
> 假设表的容量不是质数，例如：表长为 15（下标值 0 ~ 14）
>
> - 有一个特定关键字映射到 0，步长为 5
> - 探测序列：0 - 5 -10 - 0 - 5 - 10 ...，算法只尝试这三个单元，如果已经有了数据，将一直循环下去，直到程序崩溃
>
> 如果容量是一个质数，比如 13
>
> - 探测序列：0 - 5 - 10 - 2 - 7 - 12 - 4 - 9 - 1 - 6 - 11 - 3 ...，一直这样下去
>
> - 不仅不会产生循环，而且可以让数据在哈希表中更加均匀的分布
>
>   2.而链地址法中质数没有那么重要，甚至在 Java 中故意是 2 的 N 次幂
>
> Java 中的 HashMap 采用的是链地址法，哈希化采用的是公式为：index = HashCode(key) & (Length-1) 即将数据化为二进制进行与运算，而不是取余运算。这样计算机直接运算二进制数据，效率更高。但是 JavaScript 在进行较大数据的与运算时会出现问题，所以我们使用 JavaScript 实现哈希化时采用取余运算。

### 7.5 封装哈希表

#### 哈希表常见操作

- `put(key, value)` 插入或修改操作。
- `get(key)` 获取哈希表中特定位置的元素。
- `remove(key)` 删除哈希表中特定位置的元素。
- `isEmpty()` 如果哈希表中不包含任何元素，返回 trun，如果哈希表长度大于 0 则返回 false。
- `size()` 返回哈希表包含的元素个数。
- `resize(value)` 对哈希表进行扩容操作。

![img](https://img-blog.csdnimg.cn/20200927211452782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 哈希表的扩容与压缩

为什么需要扩容？

- 前面我们在哈希表中使用的是长度为 7 的数组，由于使用的是**链地址法**，**装填因子（loadFactor）**可以大于 1，所以这个哈希表可以无限制地插入新数据。
- 但是，随着**数据量的增多**，storage 中每一个 index 对应的 bucket 数组（链表）就会越来越长，这就会造成哈希表**效率的降低**。

什么情况下需要扩容？

- 常见的情况是 **loadFactor > 0.75** 的时候进行扩容。

如何进行扩容？

- 简单的扩容可以直接**扩大两倍**（关于质数，之后讨论）。
- 扩容之后所有的数据项**都要进行同步修改**。

**resize 方法**：既可以实现哈希表的扩容，也可以实现哈希表容量的压缩。

## 八、树结构（Tree）

### 8.1 什么是树

##### 树的特点

- 树一般都有一个根，连接着根的是树干；
- 树干会发生分叉，形成许多树枝，树枝会继续分化成更小的树枝；
- 树枝的最后是叶子；

现实生活中很多结构都是**树的抽象**，模拟的树结构相当于旋转 `180°` 的树。

##### 树（Tree）

由 n（n ≥ 0）个节点构成的**有限集合**。当 n = 0 时，称为**空树**。

对于任意一棵非空树（n > 0），它具备以下性质：

- 数中有一个称为**根（Root）**的特殊节点，用 **r** 表示；
- 其余节点可分为 m（m > 0）个互不相交的有限集合 T1，T2，...，Tm，其中每个集合本身又是一棵树，称为原来树的**子树（SubTree）**。

![img](https://img-blog.csdnimg.cn/20200927211458928.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 树结构对比于数组/链表/哈希表有哪些优势？

数组：

- 优点：可以通过**下标值访问**，效率高
- 缺点：
  - 如果我们想根据元素来查找对应的位置时
  - 需要先对数据进行**排序**，生成有序数组，再**二分查找**，才能提高查找效率
  - 并且在插入和删除元素时，需要大量的**位移操作**

链表：

- 优点：数据的插入和删除操作效率都很高
- 缺点：
  - **查找**效率低，需要从头开始依次查找，直到找到目标数据为止
  - 但是如果要插入和删除中间位置的数据，还是需要从头先找到对应的数据

哈希表：

- 优点：哈希表的插入/查询/删除效率都非常高；
- 缺点：
  - **空间利用率不高**，底层使用的数组中很多单元没有被利用
  - 并且哈希表中的元素是**无序**的，不能按照固定顺序遍历哈希表中的元素
  - 而且不能快速找出哈希表中**最大值或最小值**这些特殊值。

树结构：

- 优点：树结构综合了上述三种结构的优点，同时也弥补了它们存在的缺点（虽然效率不一定都比它们高），比如树结构中数据都是有序的，查找效率高；空间利用率高；并且可以快速获取最大值和最小值等。

总的来说：**每种数据结构都有自己特定的应用场景。**

##### 树的常用术语

![img](https://img-blog.csdnimg.cn/20200927211504745.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

- 节点的度（Degree）：节点的子树个数，比如节点 B 的度为 2；
- 树的度：树的所有节点中最大的度数，如上图树的度为 2；
- 叶节点（Leaf）：度为 0 的节点（也称为叶子节点），如上图的 H，E，I，J，G；
- 父节点（Parent）：度不为 0 的节点称为父节点，如上图节点 B 是节点 D 和 E 的父节点；
- 子节点（Child）：若 B 是 D 的父节点，那么 D 就是 B 的子节点；
- 兄弟节点（Sibling）：具有同一父节点的各节点彼此是兄弟节点，比如上图的 B 和 C，D 和 E 互为兄弟节点；
- 路径和路径长度：路径指的是一个节点到另一节点的通道，路径所包含边的个数称为路径长度，比如 A->H 的路径长度为 3；
- 节点的层次（Level）：规定根节点在 1 层，其他任一节点的层数是其父节点的层数加 1。如 B 和 C 节点的层次为 2；
- 树的深度（Depth）：树种所有节点中的最大层次是这棵树的深度，如上图树的深度为 4；

##### 树结构的表示方式

**最普通的表示方法**

![img](https://img-blog.csdnimg.cn/20200927211829687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

如图，树结构的组成方式类似于链表，都是由一个个节点连接构成。不过，根据每个父节点子节点数量的不同，每一个父节点需要的引用数量也不同。比如节点 A 需要 3 个引用，分别指向子节点 B，C，D；B 节点需要 2 个引用，分别指向子节点 E 和 F；K 节点由于没有子节点，所以不需要引用。

这种方法缺点在于我们无法确定某一结点的引用数。

**儿子-兄弟表示法**

![img](https://img-blog.csdnimg.cn/20200927211838255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

这种表示方法可以完整地记录每个节点的数据，优点是每一个节点中引用的数量都是确定的。如：

```
//节点A
Node{
  //存储数据
  this.data = data
  //统一只记录左边的子节点
  this.leftChild = B
  //统一只记录右边的第一个兄弟节点
  this.rightSibling = null
}

//节点B
Node{
  this.data = data
  this.leftChild = E
  this.rightSibling = C
}

//节点F
Node{
  this.data = data
  this.leftChild = null
  this.rightSibling = null
}
```

**儿子-兄弟表示法旋转**

将儿子-兄弟表示法组成的树结构顺时针旋转 45° 之后：

![img](https://img-blog.csdnimg.cn/20200927211843114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

这样就成为了一棵二叉树，由此我们可以得出结论：任何树都可以通过二叉树进行模拟。但是这样父节点不是变了吗？其实，父节点的设置只是为了方便指向子节点，在代码实现中谁是父节点并没有关系，只要能正确找到对应节点即可。

### 8.2 二叉树

#### 二叉树的概念

如果树中的每一个节点最多只能由两个子节点，这样的树就称为二叉树。

#### 二叉树的组成

- 二叉树可以为空，也就是没有节点
- 若二叉树不为空，则它由根节点和称为其左子树 TL 和右子树 TR 的两个不相交的二叉树组成

#### 二叉树的五种形态

![img](https://img-blog.csdnimg.cn/20200927211850129.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

上图分别表示：空的二叉树、只有一个节点的二叉树、只有左子树 TL 的二叉树、只有右子树 TR 的二叉树和有左右两个子树的二叉树。

#### 二叉树的特性

- 一个二叉树的第 i 层的最大节点树为：2^(i-1)，i >= 1
- 深度为 k 的二叉树的最大节点总数为：2^k - 1 ，k >= 1
- 对任何非空二叉树，若 n0 表示叶子节点的个数，n2 表示度为 2 的非叶子节点个数，那么两者满足关系：n0 = n2 + 1
  - 如下图所示：H，E，I，J，G 为叶子节点，总数为 5
  - A，B，C，F 为度为 2 的非叶子节点，总数为 4
  - 满足 5 = 4 + 1 的规律。

![img](https://img-blog.csdnimg.cn/20200927211854923.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 特殊的二叉树

##### 完美二叉树

完美二叉树（Perfect Binary Tree）也称为满二叉树（Full Binary Tree），在二叉树中，除了最下一层的叶子节点外（叶子节点没有子节点），每层节点都有 2 个子节点，这就构成了完美二叉树。

![img](https://img-blog.csdnimg.cn/20200927212530451.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 完全二叉树

完全二叉树（Complete Binary Tree）:

- 除了二叉树最后一层外，其他各层的节点数都达到了最大值；
- 并且，最后一层的叶子节点从左向右是连续存在，只缺失右侧若干叶子节点；
- 完美二叉树是特殊的完全二叉树；

在下图中，由于 D 缺失了右子节点，所以它不是完全二叉树。

![img](https://img-blog.csdnimg.cn/20200927212615919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 二叉树的数据存储

常见的二叉树存储方式为数组和链表

##### 使用数组

- 完全二叉树：按从上到下，从左到右的方式存储数据。

![img](https://img-blog.csdnimg.cn/20200927212625289.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

| 节点 | A    | B    | C    | D    | E    | F    | G    | H    | I    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 序号 | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    |

使用数组存储，取数据的时候也十分方便：左子节点的序号等于父节点序号 + 1，右子节点的序号等于父节点序号 + 2。

- 非完全二叉树：非完全二叉树需要转换成完全二叉树才能按照上面的方案存储，这样**会浪费很大的存储空间**。

![img](https://img-blog.csdnimg.cn/20200927212632614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

| 节点 | A    | B    | C    | ^    | ^    | F    | ^    | ^    | ^    | ^    | ^    | ^    | M    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 序号 | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   |

##### 使用链表

**二叉树最常见的存储方式为链表**：每一个节点封装成一个 Node，Node 中包含存储的数据、左节点的引用和右节点的引用。

![img](https://img-blog.csdnimg.cn/20200927212645912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 8.3 二叉搜索树

**二叉搜索树**（BST，Binary Search Tree），也称为**二叉排序树和二叉查找树**。

二叉搜索树是一棵二叉树，可以为空。

如果不为空，则满足以下**性质**：

- 条件 1：非空左子树的所有键值小于其根节点的键值。比如三中节点 6 的所有非空左子树的键值都小于 6；
- 条件 2：非空右子树的所有键值大于其根节点的键值；比如三中节点 6 的所有非空右子树的键值都大于 6；
- 条件 3：左、右子树本身也都是二叉搜索树；

![img](https://img-blog.csdnimg.cn/20200927212654153.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

如上图所示，树二和树三符合 3 个条件属于二叉树，树一不满足条件 3 所以不是二叉树。

总结：二叉搜索树的特点主要是**较小的值**总是保存在**左节点**上，相对**较大的值**总是保存在**右节点**上。这种特点使得二叉搜索树的查询效率非常高，这也就是二叉搜索树中“搜索”的来源。

#### 二叉搜索树应用举例

下面是一个二叉搜索树：

![img](https://img-blog.csdnimg.cn/20200927212700621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

若想在其中查找数据 10，只需要查找 4 次，查找效率非常高。

- 第 1 次：将 10 与根节点 9 进行比较，由于 10 > 9，所以 10 下一步与根节点 9 的右子节点 13 比较；
- 第 2 次：由于 10 < 13，所以 10 下一步与父节点 13 的左子节点 11 比较；
- 第 3 次：由于 10 < 11，所以 10 下一步与父节点 11 的左子节点 10 比较；
- 第 4 次：由于 10 = 10，最终查找到数据 10 。

同样是 15 个数据，在排序好的数组中查询数据 10，需要查询 10 次：

![img](https://img-blog.csdnimg.cn/20200927212707226.png#pic_center)

其实：如果是排序好的数组，可以通过二分查找：第一次找 9，第二次找 13，第三次找 15...。我们发现如果把每次二分的数据拿出来以树的形式表示的话就是二叉搜索树。这就是数组二分法查找效率之所以高的原因。

### 8.4 二叉搜索树的封装

二叉搜索树有四个最基本的属性：指向节点的根（root），节点中的键（key）、左指针（right）、右指针（right）。

![img](https://img-blog.csdnimg.cn/20200927212713614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 8.4.1 二叉搜索树的常见操作

- insert（key）：向树中插入一个新的键
- search（key）：在树中查找一个键，如果节点存在，则返回 true；如果不存在，则返回 false
- inOrderTraverse：通过中序遍历方式遍历所有节点
- preOrderTraverse：通过先序遍历方式遍历所有节点
- postOrderTraverse：通过后序遍历方式遍历所有节点
- min：返回树中最小的值/键
- max：返回树中最大的值/键
- remove（key）：从树中移除某个键

#### 8.4.2 插入数据

实现思路：

- 首先根据传入的 key 创建节点对象。
- 然后判断根节点是否存在，不存在时通过：this.root = newNode，直接把新节点作为二叉搜索树的根节点。
- 若存在根节点则重新定义一个内部方法 `insertNode()` 用于查找插入点。

insertNode() 的实现思路:

根据比较传入的两个节点，一直查找新节点适合插入的位置，直到成功插入新节点为止。

- 当 newNode.key < node.key 向左查找:
  - 情况 1：当 node 无左子节点时，直接插入：
  - 情况 2：当 node 有左子节点时，递归调用 insertNode()，直到遇到无左子节点成功插入 newNode 后，不再符合该情况，也就不再调用 insertNode()，递归停止。
- 当 newNode.key >= node.key 向右查找，与向左查找类似：
  - 情况 1：当 node 无右子节点时，直接插入：
  - 情况 2：当 node 有右子节点时，依然递归调用 insertNode()，直到遇到传入 insertNode 方法 的 node 无右子节点成功插入 newNode 为止。

测试的二叉搜索树：

![img](https://img-blog.csdnimg.cn/20200927213850517.png#pic_center)

#### 8.4.3 遍历数据

这里所说的树的遍历不仅仅针对二叉搜索树，而是适用于所有的二叉树。由于树结构不是线性结构，所以遍历方式有多种选择，常见的三种二叉树遍历方式为：

- 先序遍历；
- 中序遍历；
- 后序遍历；

还有层序遍历，使用较少。

##### 8.4.3.1 先序遍历

先序遍历的过程为：

首先，遍历根节点；
然后，遍历其左子树；
最后，遍历其右子树；

![img](https://img-blog.csdnimg.cn/20200927213856533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

如上图所示，二叉树的节点遍历顺序为：A -> B -> D -> H -> I -> E -> C -> F -> G。

##### 8.4.3.2 中序遍历

实现思路：与先序遍历原理相同，只不过是遍历的顺序不一样了。

首先，遍历其左子树；
然后，遍历根（父）节点；
最后，遍历其右子树；

![img](https://img-blog.csdnimg.cn/20200927213903738.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

输出节点的顺序应为：3 -> 5 -> 6 -> 7 -> 8 -> 9 -> 10 -> 11 -> 12 -> 13 -> 14 -> 15 -> 18 -> 20 -> 25 。其实就是从小到大排序。

##### 8.4.3.3 后序遍历

实现思路：与先序遍历原理相同，只不过是遍历的顺序不一样了。

首先，遍历其左子树；
然后，遍历其右子树；
最后，遍历根（父）节点；

![img](https://img-blog.csdnimg.cn/20200927213909783.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

输出节点的顺序应为：3 -> 6 -> 5 -> 8 -> 10 -> 9 -> 7 -> 12 -> 14 -> 13 -> 18 -> 25 -> 20 -> 15 -> 11 。

##### 8.4.3.4 总结

以遍历根（父）节点的顺序来区分三种遍历方式。比如：先序遍历先遍历根节点、中序遍历第二遍历根节点、后续遍历最后遍历根节点。

#### 8.4.4 查找数据

##### 查找最大值或最小值

在二叉搜索树中查找最值非常简单，最小值在二叉搜索树的最左边，最大值在二叉搜索树的最右边。只需要一直向左/右查找就能得到最值，如下图所示：

![img](https://img-blog.csdnimg.cn/20200927213916605.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 8.4.5 删除数据

实现思路：

第一步：先找到需要删除的节点，若没找到，则不需要删除；

首先定义变量 current 用于保存需要删除的节点、变量 parent 用于保存它的父节点、变量 isLeftChild 保存 current 是否为 parent 的左节点，这样方便之后删除节点时改变相关节点的指向。

第二步：删除找到的指定节点，分 3 种情况：

- 删除的是叶子节点；
- 删除的是只有一个子节点的节点；
- 删除的是有两个子节点的节点；

##### 8.4.5.1 删除的是叶子节点

删除的是叶子节点分两种情况：

- 叶子节点也是根节点

  当该叶子节点为根节点时，如下图所示，此时 current == this.root，直接通过：this.root = null，删除根节点。

![img](https://img-blog.csdnimg.cn/20200927213929285.png#pic_center)

- 叶子节点不为根节点

  当该叶子节点不为根节点时也有两种情况，如下图所示

![img](https://img-blog.csdnimg.cn/20200927213942159.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 8.4.5.2 删除的是只有一个子节点的节点

有六种情况：

当 current 存在左子节点时（current.right == null）：

- 情况 1：current 为根节点（current == this.root），如节点 11，此时通过：this.root = current.left，删除根节点 11；
- 情况 2：current 为父节点 parent 的左子节点（isLeftChild == true），如节点 5，此时通过：parent.left = current.left，删除节点 5；
- 情况 3：current 为父节点 parent 的右子节点（isLeftChild == false），如节点 9，此时通过：parent.right = current.left，删除节点 9；

![img](https://img-blog.csdnimg.cn/20200927213952240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

当 current 存在右子节点时（current.left = null）：

- 情况 4：current 为根节点（current == this.root），如节点 11，此时通过：this.root = current.right，删除根节点 11。
- 情况 5：current 为父节点 parent 的左子节点（isLeftChild == true），如节点 5，此时通过：parent.left = current.right，删除节点 5；
- 情况 6：current 为父节点 parent 的右子节点（isLeftChild == false），如节点 9，此时通过：parent.right = current.right，删除节点 9；

![img](https://img-blog.csdnimg.cn/20200927213957960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

##### 8.4.5.3 删除的是有两个子节点的节点

这种情况十分复杂，首先依据以下二叉搜索树，讨论这样的问题：

![img](https://img-blog.csdnimg.cn/20200927214005682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**删除节点 9**

在保证删除节点 9 后原二叉树仍为二叉搜索树的前提下，有两种方式：

- 方式 1：从节点 9 的左子树中选择一合适的节点替代节点 9，可知节点 8 符合要求；
- 方式 2：从节点 9 的右子树中选择一合适的节点替代节点 9，可知节点 10 符合要求；

![img](https://img-blog.csdnimg.cn/20200927214011461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**删除节点 7**

在保证删除节点 7 后原二叉树仍为二叉搜索树的前提下，也有两种方式：

- 方式 1：从节点 7 的左子树中选择一合适的节点替代节点 7，可知节点 5 符合要求；
- 方式 2：从节点 7 的右子树中选择一合适的节点替代节点 7，可知节点 8 符合要求；

![img](https://img-blog.csdnimg.cn/20200927214016861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**删除节点 15**

在保证删除节点 15 后原树二叉树仍为二叉搜索树的前提下，同样有两种方式：

- 方式 1：从节点 15 的左子树中选择一合适的节点替代节点 15，可知节点 14 符合要求；
- 方式 2：从节点 15 的右子树中选择一合适的节点替代节点 15，可知节点 18 符合要求；

![img](https://img-blog.csdnimg.cn/20200927214026643.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

规律总结：如果要删除的节点有两个子节点，甚至子节点还有子节点，这种情况下需要从要删除节点下面的子节点中找到一个合适的节点，来替换当前的节点。

若用 current 表示需要删除的节点，则合适的节点指的是：

- current 左子树中比 current 小一点点的节点，即 current 左子树中的最大值；
- current 右子树中比 current 大一点点的节点，即 current 右子树中的最小值；

##### 8.4.5.4 前驱&后继

在二叉搜索树中，这两个特殊的节点有特殊的名字：

- 比 current 小一点点的节点，称为 current 节点的前驱。比如下图中的节点 5 就是节点 7 的前驱；
- 比 current 大一点点的节点，称为 current 节点的后继。比如下图中的节点 8 就是节点 7 的后继；

![img](https://img-blog.csdnimg.cn/2020092721403215.png#pic_center)

查找需要被删除的节点 current 的后继时，需要在 current 的右子树中查找最小值，即在 current 的右子树中一直向左遍历查找；

查找前驱时，则需要在 current 的左子树中查找最大值，即在 current 的左子树中一直向右遍历查找。

> 因为删除节点非常负责，一些程序员都尝试避开删除操作
>
> - 它们的做法是在 Node 类中添加一个 boolean 的字段，比如名称为 isDeleted
> - 要删除一个节点时就将此字段设置为 true
> - 其他操作，如 find() 在查找之前先判断这个节点是不是标记为已删除
>
> 这样相对比较简单，每次删除节点不会改变原有的树结构。但是在二叉树的存储中，还保留着那些本该被删除掉的节点。
>
> 这种做法看似聪明，但其实是一种逃避，会造成很大空间的浪费，特别是针对数据量较大的情况。

### 8.5 二叉搜索树的缺陷

二叉搜索树作为数据存储的结构有重要的优势：

- 可以**快速地**找到给定关键字的数据项，并且可以快速地**插入和删除数据项**

但是，二叉搜索树有一个很麻烦的问题：

- 如果插入的数据是**有序的数据**，比如给初始化为 9 8 12 的二叉树插入 7 6 5 4 3，如下图

![img](https://img-blog.csdnimg.cn/20200927214037815.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

非平衡树：

- 好的二叉搜索树数据应该是**左右分布均匀**的
- 但是插入**连续数据**后，**分布并不均匀**，我们将这种树称为**非平衡树**
- 对于一棵**平衡二叉树**来说，插入/查找等操作的效率是 **O(logN)**
- 对于一棵**非平衡二叉树**来说，相当于编写了一个链表，查找效率变成了 **O(N)**

### 8.6 树的平衡性

为了能以较快的时间 O(logN) 来操作一棵树，我们需要保证树总是平衡的：

- 至少大部分是平衡的，那么时间复杂度也是接近 O(logN) 的
- 也就是说树中每个节点左边的子孙节点的个数，应该尽可能的等于右边的子孙节点的个数

常见的平衡树有哪些呢？

**AVL 树**

- AVL 树是最早的一种平衡树，它有些办法保持**树的平衡**（每个节点多存储了一个额外的数据）
- 因为 AVL 树是**平衡的**，所以时间复杂度也是 O(logN)
- 但是，每次插入/删除操作相对于红黑树效率都不高，所以**整体效率不如红黑树**

**红黑树**

- 红黑树也通过**一些特性**来保持树的平衡
- 因为是平衡树，所以时间复杂度也是 O(logN)
- 另外，插入/删除等操作，其性能要优于 AVL 树，所以现在平衡树的应用基本都是红黑树

## 九、红黑树

### 红黑树的规则

红黑书除了符合二叉搜索树的基本规则外，还添加了一些特性：

1. **节点是红色或黑色**
2. **根节点是黑色**
3. **每个叶子节点都是黑色的空节点（NIL 节点）**
4. **每个红色节点的两个子节点都是黑色（从每个叶子节点到根的所有路径上不能有两个连续的红色节点）**
5. **从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点**

### 红黑树的相对平衡

前面的约束确保了红黑树的关键特性：

- 从**根到叶子**的**最长可能路径**不会超过**最短可能路径**的**两倍长**
- 结果就是这个树**基本**是平衡的
- 虽然没有做到绝对的平衡，但是可以保证在最坏的情况下依然是高效的

为什么可以做到`最长路径不超过最短路径的两倍呢`？

- 性质 4 决定了路径不能有两个相连的红色节点
- 最短的可能路径都是黑色节点
- 最长可能路径是红色和黑色交替
- 性质 5 所有路径都有相同的数目的黑色节点（而根节点和叶子节点都是黑色，这样最长路径中间夹的红色节点一定没有黑色节点多）
- 这就表明了没有路径能多余任何其他路径的两倍长

## 参考

[JavaScript(ES6)数据结构和算法](https://www.bilibili.com/video/BV1a5411t7vZ)

# JavaScript 排序算法

## 相关概念

**稳定**：如果 a 原本在 b 前面，而 a = b，排序之后 a 仍然在 b 的前面。

**不稳定**：如果 a 原本在 b 的前面，而 a = b，排序之后 a 可能会出现在 b 的后面。

**时间复杂度**：对排序数据的总的操作次数。反映随着数据规模 n 变化时，操作次数呈现什么规律。

**空间复杂度**：是指算法在计算机内执行时所需存储空间的度量，它也是数据规模 n 的函数。

## 大 O 表示法

**企业规模的概述**

- 公司可以按照**规模**分为：小型企业/中型企业/大型企业
- 在**不说明具体员工人数或占地面积**的情况下，我们可以通过这样**大概的概念**来描述企业的规模

**大 O 表示法**：是描述性能和复杂度的一种表示方法

在**算法**的描述中，我们也可以通过**类似的**快捷方式来描述计算机算法的效率。在计算机中，这种**粗略的度量**被称作`大O表示法`。

在算法的比较过程中，我们可能喜欢说：算法 A 比算法 B 快两倍，但是这样的比较有时候并**没有意义**。因为在**数据项个数**发生变化时，**算法的效率**会跟着发生改变。

所以，通常我们使用一种**算法的速度**会如何跟随着**数据量的变化**而变化的表示方法。

### 常见的大 O 表示形式

| 符号       | 名称           |
| ---------- | -------------- |
| O(1)       | 常数的         |
| O(log(n))  | 对数的         |
| O(n)       | 线性的         |
| O(nlog(n)) | 线性和对数乘积 |
| O(n^2)     | 平方           |
| O(2^n)     | 指数的         |

![img](https://img-blog.csdnimg.cn/20200927225802651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

> 从下往上：
>
> O(1)与横坐标重叠，效率最高，O(logn)几乎与横坐标重叠，O(n)是一条直线
>
> 再向上是 O(nlogn)比 O(n)效率差一点，O(n^2)平方增长的也很快
>
> 最后是效率最差的 O(2^n)，数据增长一点，需要操作的次数就增长的非常多，这样的算法一定要优化

**推导大 O 表示法的方式**

1. 用常量 1 取代运行时间中所有的加法常量
2. 在修改后的运行次数函数中，只保留最高阶项
3. 如果最高存在且不为 1，则去除与这个项相乘的常数

## 认识排序算法

排序算法有很多：冒泡/选择/插入/归并/计数(couting sort)/基数(radix sort)/希尔/堆/桶排序

这里不一一列举它们的实现思想，而是选择了几个常见的简单排序和高级排序：

简单排序：冒泡排序 - 选择排序 - 插入排序

高级排序：希尔排序 - 快速排序

### 如何排序

**计算机排序的特点**

- 计算机不能像人一样，一眼扫过去这样通览所有的数据
- 它只能根据计算机的**比较操作原理**，在同一个时间对两个队员进行比较
- 在人类看来很简单的事情，计算机的算法却不能看到全景，因此它只能一步步解决具体问题和遵循一些简单的规则

**简单算法的主要操作**

- 比较两个数据项
- 交换两个数据项，或者复制其中一项
- 但是，每种算法具体实现的细节有所不同

#### 创建列表

- 在开始排序前，我们先来创建一个列表封装我们的数据项（ArrayList）
- 初始化数据项

## 冒泡排序

冒泡排序算法相对其他排序运行**效率较低**，但是在概念上它是排序算法中**最简单的**。因此，冒泡排序是在刚开始学习排序时，最适合学习的一种排序方式。

### 冒泡排序的思想

- 对未排序的各元素**从头到尾**依次比较**相邻的两个元素**大小关系
- 如果**左边的队员高**，则两队员**交换位置**
- 向右**移动一个位置**，比较下面两个队员
- 当走到**最右端**时, **最高的队员**一定被放在了**最右边**
- 按照这个思路，从最左端重新开始, 这次走到**倒数第二个位置**的队员即可
- 依次类推，就可以将数据排序完成

### 冒泡排序的图解

![img](https://img-blog.csdnimg.cn/20200927225859475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 代码思路分析

- 第一次找出最高人放在最后，我们需要两个两个数据项进行比较，那么这个应该是一个循环操作
- 第二次将次高的人找到放在倒数第二个位置，也是两个比较，只是不要和最后一个比较（少了一次），但是前面的两个两个比较也是一个循环操作
- 第三次...第四次...
- 这应该是一个**循环中嵌套循环**，并**且被嵌套的循环次数越来越少**的

![img](https://img-blog.csdnimg.cn/20200927230021648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 冒泡排序的效率

**冒泡排序的比较次数**

- 如果按照代码中的例子来说，一共有 7 个数字，那么每次循环时进行了几次的比较呢？
- 第一次循环 6 次比较，第二次 5 次比较，第三次 4 次比较....直到最后一趟进行了一次比较
- 对于 7 个数据项比较次数：6 + 5 + 4 + 3 + 2 + 1
- 对于 **N 个数据项比较次数**：(N - 1) + (N - 2) + (N - 3) + ... + 1 = N * (N - 1) / 2

**通过大 O 表示法推导过程得到冒泡排序的大 O 形式**

- N * (N - 1) / 2 = N²/2 - N/2，根据规则 2，只保留最高阶项，变成 N² / 2
- N² / 2，根据规则 3，去除常量，变成 N²
- 因此**冒泡排序的大 O 表示法为 O(N²)**

**冒泡排序的交换次数**

- 冒泡排序的交换次数是多少呢？平均两次比较才需要交换一次(不可能每次比较都交换一次)，N * (N - 1) / 2 / 2
- 那么交换次数为 N² / 4
- 由于常量不算在大 O 表示法中，因此，我们可以认为**交换次数的大 O 表示也是 O(N²)**

## 选择排序

选择排序改进了冒泡排序，将**交换的次数**由 O(N²) 减少到 O(N)，但是**比较的次数**依然是 O(N²)

### 选择排序的思想

- 选定**第一个索引位置**，然后和后面元素**依次比较**
- 如果**后面的元素，小于第一个索引位置**的，则**选定这个位置的元素**，再与后面的依次比较
- 一轮比较完后，将选定的元素与第一个交换，可以确定**第一个位置是最小的**
- 然后使用同样的方法把**剩下的元素逐个比较**即可
- 可以看出选择排序，**第一轮**会选出**最小值**，**第二轮**会选出**第二小的值**，直到最后

### 选择排序的图解

![img](https://img-blog.csdnimg.cn/20200927225935307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 代码思路分析

- 第一轮将第 0 位置的值取出，和后面的人（1、2、3...）依次比较，如果后面的值更小，那么就取出更小的值再去与后面的值比较
- 这样经过一轮之后，将最后取出的值与第 0 位置的值交换，这样第一个肯定是最小的值
- 第二轮将第 1 位置的值取出，和后面的值（2、3、4...）依次比较，如果后面的值更小，那么就取出更小的值再去与后面的值比较
- 这样经过第二轮后，最后与第 1 位置的值交换，这样第二个肯定是次小的人
- 第三轮... 第四轮... 直到最后就可以排好序了
- 外层循环依次取出 0、1、2、...、N-2，位置的值作为 index（N-1 不需要取了，因为只剩它一个了肯定是排好序的）
- 内层循环从 index+1 开始比较，直到最后一个

![img](https://img-blog.csdnimg.cn/20200927230054105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 选择排序的效率

**选择排序的比较次数**

- 选择排序和冒泡排序的比较次数都是 N*(N-1)/2，也就是 **O(N²)**

**选择排序的交换次数**

- 选择排序的交换次数只有 N - 1 次，用大 O 表示法就是 **O(N)**
- 所以选择排序通常认为在执行效率上是高于冒泡排序的

## 插入排序

插入排序**是简单排序中效率最好的一种**。插入排序也是学习其他高级排序的基础，比如希尔排序/快速排序，所以也非常重要。

### 插入排序的思想

**局部有序**

- 插入排序思想的核心是**局部有序**
- 比如在一个队列中的人，我们选择**其中一个作为标记的队员**
- 这个**被标记的队员左边的**所有队员已经是**局部有序**的
- 这意味着, 有一部门人是**按顺序排列好的**，有一部分还**没有顺序**

**插入排序的思路**

- 从**第一个元素**开始，该元素可以认为**已经被排序**
- 取出**下一个元素**，在已经排序的元素序列中**从后向前扫描**
- 如果**该元素（已排序）大于新元素**，将该元素移到下一位置
- 重复上一个步骤，直到找到已排序的元素小于或者等于新元素的位置
- 将新元素插入到该位置后，重复上面的步骤.

### 插入排序的图解

![img](https://img-blog.csdnimg.cn/2020092723013237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 代码思路分析

- 插入排序应该从下标值 1 开始（因为 0 位置默认可以被认为是有序的）
- 从 1 位置开始取出元素，并且判断该元素的大小和 0 位置进行比较，如果 1 位置元素小于 0 位置元素，那么交换，否则不交换
- 上面步骤执行完成后，0 - 1 位置已经排序好
- 取出 2 位置的元素，和 1 位置进行比较：
  - 如果 2 位置元素大于 1 位置元素，说明 2 位置不需要任何动作，0 - 1 - 2 已经排序好
  - 如果 2 位置元素小于 1 位置元素，那么将 1 移动到 2 的位置 ，并且 2 继续和 0 进行比较
  - 如果 2 位置元素大于 0 位置的元素，那么将 2 位置放置在 1 的位置，排序完成，0 - 1 - 2 搞定
  - 如果 2 位置元素小于 0 位置的元素，那么将 0 位置的元素移动到 1 位置，并且将 2 位置的元素放在 0 位置，0 - 1 - 2 搞定
- 按照上面的步骤，依次找到最后一个元素，直到整个数组排序完成

![img](https://img-blog.csdnimg.cn/2020092723014660.gif#pic_center)

### 插入排序的效率

**插入排序的比较次数**

- 第一趟时，需要的最多次数是 1，第二趟最多次数是 2，依次类推，最后一趟是 N-1 次
- 因此比较次数最多是 1 + 2 + 3 + ... + N - 1 = N * (N - 1) / 2
- 然而每趟发现插入点之前，**平均只有全体数据项的一半**需要进行比较
- 我们可以除以 2 得到 N * (N - 1) / 4，所以相对于选择排序，**比较次数少了一半**

**插入排序的复制次数**

- 第一趟时，需要的最多复制次数是 1，第二趟最多次数是 2，依次类推，最后一趟是 N-1 次
- 因此复制次数最多是 1 + 2 + 3 + ... + N - 1 = N * (N - 1) / 2
- 平均次数 N * (N - 1) / 4

**对于基本有序的情况**

- 对于已经有序或基本有序的数据来说，插入排序要好很多
- 当数据有序的时候，while 循环的条件总是为假，所以它变成了外层循环中的一个简单语句，执行 N-1 次
- 在这种情况下，算法运行只需要 N(N) 的时间，效率相对来说会更高
- 另外，比较次数是选择排序的一半，所以这个算法的效率是高于选择排序的，但也是 **O(N²)**

## 希尔排序

### 希尔排序的历史

**希尔排序**是**插入排序**的一种高效的**改进版**，并且**效率比插入排序要更快**

> 希尔排序按其设计者希尔（Donald Shell）的名字命名，该算法由 1959 年公布。
>
> 优先的排序算法首要条件就是速度，在简单排序出现后的很多一段时间内，人们发明了各种各样的算法，但是最终发现**算法的时间复杂度都是 O(N²)**，似乎没法超越了。
>
> 此时，计算机学术界充斥着"排序算法不可能突破 O(N²)"的声音。 就像之前普遍认为人类 100 米短跑不可能突破 10 秒大关一样。
>
> 终于有一天，一位科学家发布超越了 O(N²) 的新排序算法（后来为了纪念这个里程碑，用 Shell 来命名了该算法）
>
> 紧接着出现了好几种可以超越 O(N²) 的排序算法，我们后面将的快速排序也是其中之一

**回顾插入排序**

由于希尔排序基于插入排序，所以有必须回顾一下前面的插入排序

- 我们设想一下，在插入排序执行到**一半**的时候，**标记符左边**这部分数据项都是**排好序的**，而**标识符右边**的数据项是**没有排序的**
- 这个时候，取出指向的那个数据项，把它存储在一个临时变量中，接着，从刚刚移除的位置左边第一个单元开始，每次把有序的数据项向右移动一个单元，直到存储在临时变量中的数据项可以成功插入

**插入排序的问题**

- 假设一个**很小的数据项在很靠近右端的位置**上，这里本来应该是**较大的数据项的位置**
- 把这个**小数据项移动到左边**的正确位置，所有的**中间数据项都必须向右移动一位**
- 做坏的情况是每一轮都要对数据项进行 N 次移动，平均下来每一轮移动 N/2，N 个元素就是 N*N/2 = N²/2
- 所以我们通常认为插入排序的效率是 O(N²)
- 如果有**某种方式**，**不需要移动所有中间的数据项**，就能把较小的数据项移动到左边，那么这个算法的执行效率就会有很大的改进

### 希尔排序的思想

- 比如下面的数字：81, 94, 11, 96, 12, 35, 17, 95, 28, 58, 41, 75, 15
- 先进行分组，间隔为 5，(81, 35, 41)，(94, 17, 75)，(11, 95, 15)，(96, 28)，(12, 58)
- 然后组内进行插入排序得到新序列：35 17 11 28 12 41 75 15 96 58 81 94 95，这样可以让数字离自己的正确位置更近一步
- 再让间隔为 3 进行分组，(35, 28, 75, 58, 95)，(17, 12, 15, 81)，(11, 41, 96, 94)
- 组内进行插入排序得到新序列：28 12 11 35 15 41 58 17 94 75 81 96 95，让数字离自己的正确位置又近了一步
- 最后，让间隔为 1，也就是一般的插入排序，这个时候数字已经比最开始离自己的正确位置近了很多（基本有序），那么需要复制（移动）的次数就会减少很多

![img](https://img-blog.csdnimg.cn/20200927230301703.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

选择合适的增量

- 在希尔排序的原稿中，他建议的初始间距是 N / 2，简单的把每趟排序分成两半
- 也就是说，对于 N = 100 的数组，增量间隔序列为：50, 25, 12, 6, 3, 1
- 这个方法的好处是不需要在开始排序前为找合适的增量而进行任何的计算

### 代码思路分析

1.获取数组的长度

2.计算第一次的间隔，我们按照希尔提出的间隔实现

3.增量不断变小，大于 1 就继续改变增量

4.实际上就是实现了每组值内部的插入排序

- 外层循环，保存临时变量，j 位置从 i 开始，保存该位置的值到变量 temp 中

- 内层循环，j - gap >= 0（j - gap > -1）并且 temp 小于 this.array[j - gap]，那么就进行复制（移动）

- 将 j 位置设置为变量 temp

  5.每次 while 循环后都重新计算新的间隔（除以 2）

![img](https://img-blog.csdnimg.cn/20200930225122972.gif#pic_center)

### 希尔排序的效率

希尔排序的效率跟增量是有关系的

但是，它的效率证明非常困难，甚至某些增量的效率到目前依然没有被证明出来

但是经过统计，希尔排序使用原始增量，**最坏的情况下时间复杂度为 O(N²)，通常情况下都要好于 O(N²)**

总之，我们使用希尔排序大多数情况下效率都高于简单排序，甚至在合适的增量和 N 的情况下，还要好于快速排序

## 快速排序

**快速排序**几乎可以说是**目前所有排序算法**中，**最快**的一种排序算法。

当然，没有任何一种算法是在任意情况下都是最优的，比如希尔排序确实在某些情况下可能好于快速排序。但是大多数情况下，快速排序还是比较好的选择。

### 认识快速排序

- **希尔排序**相当于**插入排序**的升级版，**快速排序**其实是我们学习过的最慢的**冒泡排序**的升级版
- 我们知道冒泡排序需要经过很多次交换，才能在一次循环中，将**最大值**放在正确的位置
- 而快速排序可以在一次循环中（其实是递归调用）找出某个元素的正确位置，并且该元素之后不需要任何移动

### 快速排序的思想

快速排序最重要的思想是**分而治之**

比如我们有这样一堆数字需要排序（13,81,92,43,65,31,57,26,75,0）

1. 从其中选出了 65（其实可以是选出任意的数字）
2. 通过算法：将所有小于 65 的数字放在 65 的左边，将所有大于 65 的数字放在 65 的右边
3. 递归的处理左边的数据（比如你选择 31 来处理左侧），递归的处理右边的数据（比如选择 75 来处理右侧，当然选择 81 可能更合适）
4. 排序完成

![img](https://img-blog.csdnimg.cn/2020092723052462.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

**和冒泡排序的不同**

- 我们选择的 65 可以一次性将它放在最正确的位置，之后不需要任何移动
- 冒泡排序需要从开始位置两个两个比较，如果第一个就是最大值，它需要一直向后移动，直到走到最后
- 也就是即使已经找到了最大值，也需要不断继续移动最大值，而插入排序对数字的定位是一次性的

### 快速排序的枢纽的实现

在快速排序中有一个很重要的步骤就是选取枢纽（即 pivot 也被称为基准）

如何选择才是最合适的枢纽呢？

- 一种方案是直接**选择第一个元素**作为枢纽

  第一个作为枢纽在某些情况下，效率并不是特别高

- 另一种方案是**使用随机数**

  随机取 pivot？但是随即函数本身就是一个耗性能的操作

- 另一种比较优秀的解决方案，**取头、中、尾的中位数**

  例如 8、12、3 的中位数就是 8

#### 代码思路分析

封装一个用于选择出来合适的枢纽的函数

该函数要求传入 left 和 right，这样可以根据 left 和 right 求出一个 center，在选择它们三者的中位数

1. 根据 left/right 求出 center
2. 将 left 放在最前面，将 center 放在中间，将 right 放在最右边
3. 这里有一个巧妙的操作, 我们将 pivot 值放在了 right 紧挨着的左边一位

- 这样操作的原因是 pivot 作为中位值一定比 right 小，在之后遍历的时候不需要再和 right 比较交换，pivot 的值就不需要移动来移动去
- 可以在最后选定位置后，直接将 pivot 交换到正确的位置即可（也是最终的位置）

1. 返回选择出来的枢纽

### 快速排序的实现

#### 代码思路分析

这里有两个函数：quickSort 和 quickSortRec

- 外部调用 quickSort
- 内部递归（recusion）调用 quickSortRec

quickSortRec：

1.left >= right 是递归的结束条件

2.调用 median(left, right) 从三个数中获取枢纽值

3.重点代码

1）使用两个 while 循环（最外面还有一个 while(true)）查找合适的 i（大于枢纽的值）和合适的 j（小于枢纽的值）

3）交换 i 和 j 位置的值

4）当 i < j 的时候，两边查找到了同一个位置，这个时候 break 停止循环

4.跳出循环后，此时查找到的 i 位置（必须是 i 位置，因为 i 和 j 可能不指向同一个值）正是 pivot 应该所在的位置，和 pivot 替换即可

- 为什么将 i 位置可以换到最后呢？万一它比 pivot 小呢？

- 这是因为我们在 while (this.array[++i] < pivot) 先循环的是 i，而不是 j。这意味着什么呢？

- 意味着：i 找到一个值，跳出第一个循环，这个值必然是大于 pivot。而 j 可能会继续向前，越过 i 的位置找到一个小于 pivot 的值然后跳出第二个循环

- 但是，这个时候已经不满足 i < j，i、j 的值不需要继续进行交换了，直接退出即可

- 而退出后，i 位置的数值是一定大于 pivot 的，所以可以将其换到后面

  5.递归调用 quickSortRec 函数，将 left, i - 1 传入就是左半部分值排序；将 i + 1, right 传入就是右半部分的值的排序

![img](https://img-blog.csdnimg.cn/20200927234520904.gif#pic_center)

### 快速排序的效率

**快速排序的最坏情况效率**

- 什么情况下会有最坏的效率呢？就是每次选择的枢纽都是最左边或者最后边的
- 那么效率等同于冒泡排序
- 而我们的例子可能有最坏的情况吗？是不可能的，因为我们是选择三个值的中位值

**快速排序的平均效率**

- 快速排序的平均效率是 **O(N \* logN)**
- 虽然其他某些算法的效率也可以达到 O(N * logN)，但是快速排序是最好的

## 归并排序

### 归并排序的思想

- 归并排序采用的是分治的思想，首先是**“分”**
- 将一个数组**反复二分**为两个小数组，**直到每个数组只有一个元素**
- 其次是**“治”**，从最小数组开始，**两两按大小顺序合并**，直到并为原始数组大小

### 归并排序的图解

![img](https://img-blog.csdnimg.cn/20200930230144784.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 代码思路分析

这里有两个函数：mergeSort 和 merge

- 外部调用/递归调用 mergeSort，分
- 内部递归调用 merge，治

递归调用 mergeSort 函数，将需要二分的 arr，这个 arr 的第一个元素位置 low，以及最后一个元素位置 high 传入

- 如果 low === high 就直接返回不需再分
- 计算二分的中间值的位置 mid，即分出来左边组的最后一个元素的位置
- 递归调用 mergeSort，将左子序列（当前 arr，left，mid）传入，一直递归二分下去，直到分到最后只有一个元素时 return，接着执行下一行代码，递归调用 mergeSort，将右子序列（当前 arr，mid + 1，right）传入。

递归调用 merge(arr, low, high)，将每一层分出来的子序列合并（递归过程中，同一层 mergeSort 和 merge 函数传入的 arr 是相同的）

- 计算 mid 中间值，左子序列的第一个元素位置 left = low，右子序列的第一个元素位置 right = mid + 1
- 创建空数组用来临时存放排好的元素
- 三个 while 循环：
  - 第一个：两个子序列都没排完，left <= mid && right <= high，arr[left] 和 arr[right] 比较，哪个小就 push 哪个到空数组中
  - 第二个：经过上面的循环，left <= mid 左子序列还没排完，依次 push，result.push(arr[left++])
  - 第三个：经过上面的循环，right <= high 右子序列还没排完，依次 push，result.push(arr[right++])
- splice 将临时存储的排好的序列替换原来的序列

![img](https://img-blog.csdnimg.cn/20200930225229147.gif#pic_center)

### 归并排序的效率

归并排序是一种稳定的排序方法。和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是**O(nlogn)** 的时间复杂度。代价是需要额外的内存空间。

## 堆排序

**堆排序是将数据看成是完全二叉树、根据完全二叉树的特性来进行排序的一种算法**

### 堆（heap）

要满足的条件：

1. 是一个完全二叉树

2. 大顶（根）堆：parent > children，**节点的元素都不小于其孩子**

   小顶（根）堆：parent < children，**节点的元素都不大于其孩子**

将一棵二叉树转化为堆的过程就是堆化（heapify）

### 堆排序的思想

完全二叉树有个特性：从任何一个节点 i 出发，都可以通过计算得到这个节点的父节点与两个子节点

- 父节点 = Math.floor( (i - 1) / 2 )
- 左子节点 = 2 * i + 1
- 右子节点 = 2 * (i + 1)

这里讨论大顶堆：

- 将待排序的数组构造成一个大顶堆。此时整个数组的最大值就是堆顶的根节点。
- 将它移走，其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值。
- 然后将剩余的 `n-1` 个元素又重新构造成堆，这样就又能得到次大值。
- 如此反复操作，直到只剩余一个元素，就能得到一个有序数组了。

### 堆排序的图解

![img](https://img-blog.csdnimg.cn/20200930231350660.gif#pic_center)

### 代码思路分析

1.大顶堆调整（Max-Heapify），将堆的末端子节点做调整，使得子节点永远小于父节点；

- 计算当前节点的左右子节点的下标，并把当前节点位置看成是最大的
- 判断左子节点是否比当前节点的值更大
- 判断右子节点是否比当前节点的值更大
- 如果三者中，当前节点值不是最大的，就交换父节点与最大子节点，并且由于一次调整后，仍有可能出现违反大顶堆的性质，所以需要递归地进行调整，直到整个堆都满足了条件。

![img](https://img-blog.csdnimg.cn/20200930225545549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

2.创建大顶堆（Build-Max-Heap），将堆中所有数据调整位置，使其成为大顶堆；

因为大顶堆调整（Max-Heapify）能够保证下标为 `i` 的节点之后的节点都满足大顶堆的性质，所以我们要自下而上地调用大顶堆调整（Max-Heapify）

- 创建大顶堆（Build-Max-Heap）
- 从下标为 Math.floor((length - 1) / 2) 处（最后一个有子节点的父节点）开始循环调用大顶堆调整（Max-Heapify）

![img](https://img-blog.csdnimg.cn/20200930225959979.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

3.堆排序（Heap-Sort）是接口算法，移除在堆顶的根节点，并做大顶堆调整的迭代运算。

- 先调用创建大顶堆（Build-Max-Heap）将数组改造为大顶堆
- 然后进入迭代（for 循环）
  - 迭代中先将堆顶与堆底元素交换，并将堆长度缩短
  - 继而重新调用大顶堆调整（Max-Heapify）保持大顶堆性质。

因为堆顶元素必然是堆中最大的元素，所以每一次操作之后，堆中存在的最大元素会被分离出堆，循环完所有元素，数组排序完成。

![img](https://img-blog.csdnimg.cn/20200930225600648.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 堆排序的效率

堆排序的运行时间主要是消耗在初始构建堆和重建堆时的反复筛选上。

总体来说，堆排序的时间复杂度为 **O(nlogn)**。由于堆排序对原始数组的排序状态并不敏感，因此它无论最好、最坏还是平均时间复杂都为 **O(nlogn)**。这在性能上显然要优于冒泡、简单选择、直接插入等复杂度为 `O(n^2)` 的算法了。

另外，由于初始化构建堆所需的比较次数较多，因此它并不适合元素个数较少的数组。

## 总结

![img](https://img-blog.csdnimg.cn/20200927234515113.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

## 参考

[coderwhy 的 JavaScript 数据结构与算法](https://www.bilibili.com/video/BV1x7411L7Q7)

[浅解前端必须掌握的算法（五）：堆排序（下）](https://juejin.im/post/6844903633796988936)

[十大经典排序算法（动图演示）](https://www.cnblogs.com/onepixel/p/7674659.html)