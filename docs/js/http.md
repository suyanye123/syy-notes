# http协议概括

![image-20210817120711057](C:\Users\喻楠\AppData\Roaming\Typora\typora-user-images\image-20210817120711057.png)

一个浏览器到底是如何工作的？

实际上，对浏览器的实现者来说，他们做的事情，就是把一个 URL 变成一个屏幕上显示的网页。

这个过程是这样的：

1. 浏览器使用 HTTP 或 HTTPS 协议**向服务端请求页面**；
2. 将请求回来的 HTML 代码经过**解析构建成 DOM 树**；
3. **计算**DOM 树上的**CSS 属性**；
4. 最后根据 CSS 属性对元素逐个进行**渲染得到**内存中的**位图**（排版）；
5. 可选的步骤：**对位图**进行**合成**，这会极大地增加后续绘制的速度；
6. 合成后，再**绘制到界面上**。

概念解释：

浏览器首先使用 HTTP 协议或 HTTPS 协议，**向服务端请求页面**。

**解析**请求回来的 **HTML 代码**：把字符流拆成了词（token）；

**构建DOM 树**：使用栈来把词（token）流构建成 DOM 树。

**CSS 计算**是把 CSS 规则应用到 DOM 树上，为 DOM 结构添加显示相关属性的过程。

文字、图片、图形、表格等等，我们把浏览器确定它们位置的过程，叫作**排版**。

浏览器中**渲染**这个过程，就是把每一个元素对应的盒变成位图。

渲染过程不会把子元素渲染到位图上面，**合成**的过程，就是为一些元素创建一个“合成后的位图”（我们把它称为合成层），把一部分子元素渲染到合成的位图上面。

**绘制**是把“位图最终绘制到屏幕上，变成肉眼可见的图像”的过程。

其中，网络通讯的部分：

## HTTP 协议

浏览器首先要做的事就是根据 URL 把数据取回来，取回数据使用的是 HTTP 协议（实际这个过程之前还有 DNS 查询）。

HTTP 协议是基于 TCP 协议出现的。TCP 协议是一条双向的通讯通道。HTTP 在 TCP 的基础上，规定了 Request-Response 的模式。这个模式决定了通讯必定是由浏览器首先发起的。

在 TCP 通道中传输的，完全是文本。

```
GET / HTTP/1.1
Host: www.woc12138.com
```

请求部分：第一行被称为 request line。分为三个部分，HTTP Method（请求方法）、请求路径和请求的协议版本。

```
HTTP/1.1 200 OK
Server: nginx/1.14.0 (Ubuntu)
Date: Tue, 19 May 2020 06:51:11 GMT
Content-Type: text/html
Content-Length: 2220
Last-Modified: Sun, 17 May 2020 17:07:09 GMT
Connection: keep-alive
Vary: Accept-Encoding
ETag: "5ec16f3d-8ac"
Accept-Ranges: bytes

<!DOCTYPE html><html>
...
</html>
```

响应部分：第一行被称作 response line，也分为三个部分，协议版本、状态码和状态文本。

紧随在 request line 或者 response line 之后，是请求头 / 响应头，这些头由若干行组成，每行是用冒号分隔的名称和值。

在头之后，以一个空行（两个换行符）为分隔，是请求体 / 响应体，请求体可能包含文件或者表单数据，响应体则是 HTML 代码。

### HTTP Method（方法）

即 request line 里面的方法部分。这里的方法跟我们编程中的方法意义类似，表示我们此次 HTTP 请求希望执行的操作类型。方法有以下几种定义：

- GET
- POST
- HEAD
- PUT
- DELETE
- CONNECT
- OPTIONS
- TRACE

浏览器通过地址栏访问页面都是 GET 方法。表单提交产生 POST 方法。

HEAD 跟 GET 类似，只返回请求头，多数由 JS 发起。

PUT 和 DELETE 分别表示添加资源和删除资源，但这只是语义上的约定并没有强约束。

CONNECT 多用于 HTTPS 和 WebSocket。

OPTIONS 和 TRACE 一般用于调试，多数线上服务都不支持。

#### GET、POST 的区别

**GET** 方法的特点：

1. **GET**用于信息获取，是安全和幂等的。

> 安全性：指的是非修改信息，即该操作用于获取信息而非修改信息。（**GET** 请求一般不应产生副作用，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态）
>
> 幂等性：指的是无论调用这个**URL** 多少次，都不会有不同的结果的 **HTTP** 方法。

1. **GET** 是会被浏览器主动缓存的，如果下一次传输的数据相同，那么就会返回缓存中的内容，以求更快地展示数据。
2. **GET** 方法的 **URL** 一般都具有长度限制，但是需要注意的是 **HTTP** 协议中并未规定 **GET** 请求的长度。 这个长度限制主要是由浏览器和 Web 服务器所决定的，并且各个浏览器对长度的限制也各不相同 。
3. **GET** 方法只产生一个 **TCP** 数据包，浏览器会把请求头和请求数据一并发送出去，服务器响应 200 ok(返回数据)。

**POST** 方法的特点：

1. **POST** 表示可能会改变服务器上的资源的请求。
2. **POST** 方法因为有可能修改服务器上的资源，所以它是不符合安全和幂等性的。
3. **POST** 是将请求信息放置在请求数据中的。
4. 因为 **POST** 方法的请求信息是放置在请求数据中的，所以它的请求信息是没有长度限制的。
5. **POST** 方法会产生两个 **TCP** 数据包，浏览器会先将请求头发送给服务器，待服务器响应 100 continue，浏览器再发送请求数据，服务器响应 200 ok(返回数据)。这么看起来 **GET** 请求的传输会比 **POST** 快上一些（因为**GET** 方法只发送一个 **TCP** 数据包），但是实际上在网络良好的情况下它们的传输速度基本相同。

**区别**：

**GET**方法和 **POST** 方法有着各自的特点，它们在外在的表现上似乎是有着诸多的不同，但是实际上，**它们的本质是一样的，并无区别**。

也就是说，**GET**和 **POST** 所做的事其实是一样的，如果你给 **GET** 加上请求数据，给 **POST** 加上 **URL** 参数，这在技术上是完全可行的。

但是为了方便管理，所以在 HTTP 协议中，就会对这些不同的请求设置不同的类别。

> 例如单纯获取资源的请求就规定为 GET、修改服务器资源的请求就规定为 POST，并且也对它们的请求报文的格式做出了相应的要求（比如请求参数 GET 位于 URL 而 POST 则位于请求数据中）。

#### PUT、POST 的区别

**PUT** 的实际语义是“replace”，是幂等的。PUT 的请求体应该是完整的资源，包括 id 在内。

服务器应该先根据请求提供的 id 进行查找，如果存在一个对应 id 的元素，就用请求中的数据**整体替换**已经存在的资源；如果没有，就用“把这个 id 对应的资源从`空`替换为`请求数据`。直观看起来就是`创建`了。

至于到底用 PUT 还是 POST 创建资源，完全要看是不是提前可以知道资源所有的数据（尤其是 id），以及是不是完整替换。对于那些 id 是服务器端自动生成的场景，POST 更合适一些。

### HTTP Status code（状态码）和 Status text（状态文本）

常见的状态码有以下几种：

- 1xx：临时回应，表示客户端应继续。
- 2xx：请求成功。
  - 200：请求成功。
- 3xx：请求的目标有变化，需要客户端进一步处理。
  - 301&302：永久性与临时性跳转。
  - 304：跟客户端缓存没有更新。
- 4xx：客户端请求错误。
  - 403：无权限。
  - 404：请求的页面不存在。
- 5xx：服务端请求错误。
  - 500：服务器端错误。
  - 503：服务端暂时性错误，可以一会儿再试。

**1xx** 系列的状态码是非常陌生的，原因是 1xx 的状态被浏览器 HTTP 库直接处理掉了，不会让上层应用知晓。

**3xx** 系列比较复杂，301 和 302 两个状态表示当前资源已经被转移，只不过一个是永久性转移，一个是临时性转移。实际上 301 更接近于一种报错，提示客户端下次别来了。

**304** 是一个每个前端必知必会的状态，产生这个状态的原因是：**客户端本地已经有缓存的版本，并且在 Request 中告诉了服务端，当服务端通过时间或者 tag，发现没有更新的时候，就会返回一个不含 body 的 304 状态**。

### HTTP Head (HTTP 头)

#### Request Header

![img](https://static001.geekbang.org/resource/image/2b/a2/2be3e2457f08bdf624837dfaee01e4a2.png)

#### Response Header

![img](https://static001.geekbang.org/resource/image/ef/c9/efdeadf27313e08bf0789a3b5480f7c9.png)

### HTTP Request Body

HTTP 请求的 body 主要用于提交表单场景。实际上，HTTP 请求的 body 是比较自由的，只要浏览器端发送的 body 服务端认可就可以了。一些常见的 body 格式是：

- application/json
- application/x-www-form-urlencoded
- multipart/form-data
- text/xml

我们使用 HTML 的 `form` 标签提交产生的 HTML 请求，默认会产生 application/x-www-form-urlencoded 的数据格式，当有文件上传时，则会使用 multipart/form-data。

## HTTPS

在 HTTP 协议的基础上，HTTPS 和 HTTP2 规定了更复杂的内容，但是它基本保持了 HTTP 的设计思想，即：使用上的 Request-Response 模式。

HTTPS 有两个作用，一是**确定请求的目标服务端身份**，二是**保证传输的数据不会被网络中间节点窃听或者篡改**。

HTTPS 是使用加密通道来传输 HTTP 的内容。但是 HTTPS 首先与服务端建立一条 TLS 加密通道。TLS 构建于 TCP 协议之上，它实际上是对传输的内容做一次加密，所以从传输内容上看，HTTPS 跟 HTTP 没有任何区别。

## HTTP 2

HTTP 2 是 HTTP 1.1 的升级版本。

HTTP 2.0 最大的改进有两点，一是**支持服务端推送**，二是**支持 TCP 连接复用**。

HTT2 还有一个很重要的特性：使用二进制代理文本进行传输，极大提高了传输的效率。

**服务端推送**能够在客户端发送第一个请求到服务端时，提前把一部分内容推送给客户端，放入缓存当中，这可以避免客户端请求顺序带来的并行度不高，从而导致的性能问题。

**TCP 连接复用**，则使用同一个 TCP 连接来传输多个 HTTP 请求，避免了 TCP 连接建立时的三次握手开销，和初建 TCP 连接时传输窗口小的问题。





# 网络协议详解



![Http协议请求--响应](https://upload-images.jianshu.io/upload_images/24295319-5be52089c8c8e23f?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 引言

HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网服务器传输超文本到本地浏览器的传送协议。HTTP 是基于 TCP/IP 协议通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。

![本文框架图](https://upload-images.jianshu.io/upload_images/24295319-63940358e136b951?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 一、Http的特点

1.**简单快速**：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、PUT、DELETE、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。

2.**灵活**：HTTP允许传输任意类型的数据对象。

3.**无连接**：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。

4.**无状态**：**HTTP协议是无状态的，HTTP 协议自身不对请求和响应之间的通信状态进行保存。任何两次请求之间都没有依赖关系。**直观地说，就是每个请求都是独立的，与前面的请求和后面的请求都是没有直接联系的。协议本身并不保留之前一切的请求或 响应报文的信息。**这是为了更快地处理大量事务，确保协议的可伸缩性，而特意把 HTTP 协议设计成如此简单的。**

![HTTP协议是无状态的](https://upload-images.jianshu.io/upload_images/24295319-b3374ff38879d568?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## 二、Http报文

Http报文包括请求报文和响应报文两大部分，其中请求报文由请求行（request line）、请求头（header）、空行和请求体四个部分组成。而响应报文由状态行、响应头部、空行和响应体四个部分组成。接下来我们详细介绍下请求报文的各个部分及其作用。

![请求报文](https://upload-images.jianshu.io/upload_images/24295319-e2ced9f403ef5d6b?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 1.请求行，用来说明请求类型,要访问的资源以及所使用的HTTP版本。

```
POST  /chapter17/user.html HTTP/1.1
```

以上代码中“POST ”代表请求方法，“/chapter17/user.html”表示URI，“HTTP/1.1”代表协议和协议的版本。现在比较流行的是Http1.1版本

### 2.请求头由关键字/值对组成，每行一对，关键字和值用英文冒号“:”分隔。

请求头部通知服务器有关于客户端请求的信息。它包含许多有关的客户端环境和请求正文的有用信息。其中比如：
**Host，表示主机名，虚拟主机；
Connection,HTTP/1.1增加的，使用keepalive，即持久连接，一个连接可以发多个请求；
User-Agent，请求发出者，兼容性以及定制化需求。**

### 3.最后一个请求头之后是一个空行，这个行非常重要，它表示请求头已经结束，接下来的是请求正文。

### 4.请求体，可以承载多个请求参数的数据

```
name=tom&password=1234&realName=tomson
```

上面代码，承载着name、password、realName三个请求参数。

## 三、HTTP请求方法

*   GET 请求指定的页面信息，并返回实体主体。
*   HEAD 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头
*   POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。
*   PUT 从客户端向服务器传送的数据取代指定的文档的内容。
*   DELETE 请求服务器删除指定的页面。

## 四、GET与POST区别

*   GET在浏览器回退时是无害的，而POST会再次提交请求
*   GET请求会被浏览器主动缓存，而POST不会，除非手动设置
*   GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留
*   GET请求在URL中传送的参数是有长度限制的，而POST没有限制
*   GET参数通过URL传递，POST放在Request body中

## 五、Http状态码

状态代码有三位数字组成，第一个数字定义了响应的类别，共分五种类别:

*   1xx：指示信息--表示请求已接收，继续处理
*   2xx：成功--表示请求已被成功接收、理解、接受
*   3xx：重定向--要完成请求必须进行更进一步的操作
*   4xx：客户端错误--请求有语法错误或请求无法实现
*   5xx：服务器端错误--服务器未能实现合法的请求

比如我们平时常见两种出错的状态码：

```
403 Forbidden                 //对被请求页面的访问被禁止
404 Not Found                 //请求资源不存在，比如：输入了错误的URL
```

## 六、持久连接

### 1.为什么需要持久连接

**HTTP协议的初始版本中，每进行一次HTTP通信就要断开一次TCP连接**。以当年的通信情况来说，因为都是些容量很小的文本传输，所以即使这样也没有多大问题。可随着 HTTP 的 普及，文档中包含大量图片的情况多了起来。比如，使用浏览器浏览一个包含多张图片的 HTML 页面时，在发送请求访问 HTML 页面资源的同时，也会请 求该 HTML 页面里包含的其他资源。因此，**每次的请求都会造成无谓的 TCP 连接建立和断开，增加通信量的 开销。**
![](https://upload-images.jianshu.io/upload_images/24295319-0839841677c2e8ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

### 2.持久连接的特点

为解决上述 TCP 连接的问题，HTTP/1.1 和一部分的 HTTP/1.0 想出了持久连接（HTTP Persistent Connections，也称为 HTTP keep-alive 或 HTTP connection reuse）的方法。持久连接的特点是，**只要任意一端没有明确提出断开连接，则保持TCP连接状态。**

![建立 1 次 次 TCP 连接后进行多次请求和响应的交互](https://upload-images.jianshu.io/upload_images/24295319-9bd34e0b2a4423f4?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**持久连接的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。另外， 减少开销的那部分时间，使 HTTP 请求和响应能够更早地结束，这样 Web 页面的显示速度也就相应提高了。**
在 HTTP/1.1 中，所有的连接默认都是持久连接，但在 HTTP/1.0 内并未标准化。虽然有一部分服务器通过非 标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需 要支持持久连接。

## 七、管线化

持久连接使得多数请求以管线化（pipelining）方式发送成为可能。从前发送请求后需等待并收到响应，才能 发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。
**这样就能够做到同时并行发送多个请求，而不需要一个接一个地等待响应了。通俗地讲，请求打包一次传输过去，响应打包一次传递回来。管线化的前提是在持久连接下。**

![不等待响应，直接发送下一个请求 ](https://upload-images.jianshu.io/upload_images/24295319-2a8342e5d430410b?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

假如当请求一个包含 10 张图片的 HTML Web 页面，**与挨个连接相比，用持久连接可以让请求更快结束。 而管线化技术则比持久连接还要快**。请求数越多，时间差就越明显。客户端需要请求这十个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求，以此类推，而管道机制则是允许浏览器同时发出这十个请求，但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。
于是在使用持久连接的情况下，某个连接上消息的传递类似于

**请求1->响应1->请求2->响应2->请求3->响应3**

管线化方式发送变成了类似这样：

**请求1->请求2->请求3->响应1->响应2->响应3**



## TCP的三次握手和四次挥手

### 五层因特网协议栈

- 应用层

  http、telnet

- 传输层

  TCP、UDP

- 网络层

  IP

- 链路层

- 物理层

### 长连接与短连接

**短连接**就是一次 TCP 请求得到结果后,连接马上结束。

> 连接->传输数据->关闭连接

**长连接**并不马上断开,而一直保持着,直到长连接 TIMEOUT。长连接可以避免不断的进行 TCP 三次握手和四次挥手。

> 连接->传输数据->保持连接 -> 传输数据-> ... ->关闭连接。

#### 应用场景

**长连接**：**多用于操作频繁，点对点的通讯，而且连接数不能太多情况**。每个 TCP 连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，下次处理时直接发送数据包就 OK 了，不用建立 TCP 连接。

> 例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket 创建也是对资源的浪费。

**短连接**：而像 WEB 网站的 http 服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像 WEB 网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以**并发量大，但每个用户无需频繁操作情况下需用短连好**。

### 三次握手

TCP 报文中比较重要的字段：

（1）标志位（Flags）：6 个

> - URG：紧急指针（urgent pointer）有效。
> - ACK：确认序号有效。
> - PSH：接收方应该尽快将这个报文交给应用层。
> - RST：重置连接。
> - SYN：发起一个新连接。
> - FIN：释放一个连接。

（2）序号（sequence number）：seq 序号，用来标识从 TCP 源端向目的端发送的字节流，发起方发送数据时对此进行标记。

（3）确认号（acknowledgement number）：ack 序号，只有 ACK 标志位为 1 时，确认序号字段才有效，ack=seq+1。

三次握手即 TCP 连接的建立。这个连接必须是一方主动打开，另一方被动打开的。

![img](https://img-blog.csdnimg.cn/20200524180154356.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70)

握手之前主动打开连接的客户端结束 CLOSED 阶段，被动打开的服务器端也结束 CLOSED 阶段，并进入 LISTEN 阶段。随后开始`三次握手`：

1. 首先**客户端向服务器端发送一段 TCP 报文**。

   > 标记位为 SYN，表示“**请求建立新连接**”;序号为 seq=x（x 一般为 1）；随后**客户端进入 SYN-SENT 阶段**。

2. **服务器端**接收到来自客户端的 TCP 报文之后，**结束 LISTEN 阶段**。并**返回一段 TCP 报文**。

   > 标志位为 SYN 和 ACK，表示“**确认客户端的报文 seq 序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接**”（即告诉客户端，服务器收到了你的数据）；序号为 seq=y；确认号为 ack=x+1，表示收到客户端的序号 seq 并将其值加 1 作为自己确认号 ack 的值；随后**服务器端进入 SYN-RCVD 阶段**。

3. 客户端接收到来自服务器端的确认收到数据的 TCP 报文之后，明确了从客户端到服务器的数据传输是正常的，结束 SYN-SENT 阶段。并**返回最后一段 TCP 报文。**

   > 标志位为 ACK，表示“**确认收到服务器端同意连接的信号**”（即告诉服务器，我知道你收到我发的数据了）；序号为 seq=x+1，表示收到服务器端的确认号 Ack，并将其值作为自己的序号值；确认号为 ack=y+1，表示收到服务器端序号 seq，并将其值加 1 作为自己的确认号 ack 的值；**随后客户端进入 ESTABLISHED 阶段**。

在客户端与服务器端传输的 TCP 报文中，**双方的确认号 ack 和序号 seq 的值，都是在彼此 ack 和 seq 值的基础上进行计算的**，这样做保证了 TCP 报文传输的连贯性。一旦出现某一方发出的 TCP 报文丢失，便无法继续"握手"，以此确保了"三次握手"的顺利完成。

#### 为什么要进行第三次握手

1. 防止服务器端开启一些无用的连接增加服务器开销
2. 防止已失效的连接请求报文段突然又传送到了服务端，产生错误。

> 如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

### 四次挥手

四次挥手即 TCP 连接的释放(解除)。连接的释放必须是一方主动释放，另一方被动释放。

![img](https://img-blog.csdnimg.cn/20200524180209575.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70)

挥手之前主动释放连接的客户端结束 ESTABLISHED 阶段。随后开始`四次挥手`：

1. 首先**客户端想要释放连接，向服务器端发送一段 TCP 报文**。

   > 标记位为 FIN，表示“**请求释放连接**“；序号为 seq=u；随后**客户端进入** FIN-WAIT-1 阶段(**半关闭阶段**)。并且**停止在客户端到服务器端方向上发送数据**，但是客户端仍然能接收从服务器端传输过来的数据。(这里不发送的是正常连接时传输的数据(非确认报文)，而不是一切数据，所以客户端仍然能发送 ACK 确认报文)

2. 服务器端接收到从客户端发出的 TCP 报文之后，确认了客户端想要释放连接，随后服务器端结束 ESTABLISHED 阶段，**进入**CLOSE-WAIT 阶段（**半关闭状态**）并**返回一段 TCP 报文**。

   > 标记位为 ACK，表示**“接收到客户端发送的释放连接的请求**”；序号为 seq=v；确认号为 ack=u+1，表示是在收到客户端报文的基础上，将其序号 seq 值加 1 作为本段报文确认号 ack 的值。

3. 服务器端自从发出 ACK 确认报文之后，经过 CLOSED-WAIT 阶段，**做好了释放服务器端到客户端方向上的连接准备，再次向客户端发出一段 TCP 报文**。

   > 标记位为 FIN，ACK，表示“**已经准备好释放连接了**”。注意：这里的 ACK 并不是确认收到服务器端报文的确认报文。序号为 seq=w；确认号为 ack=u+1；表示是在收到客户端报文的基础上，将其序号 seq 值加 1 作为本段报文确认号 ack 的值。随后**服务器端结束 CLOSE-WAIT 阶段，进入 LAST-ACK 阶段**。并且**停止在服务器端到客户端的方向上发送数据**，但是服务器端仍然能够接收从客户端传输过来的数据。

4. 客户端收到从服务器端发出的 TCP 报文，确认了服务器端已做好释放连接的准备，结束 FIN-WAIT-2 阶段，进入 TIME-WAIT 阶段，并**向服务器端发送一段报文**。

   > 标记位为 ACK，表示“**接收到服务器准备好释放连接的信号**”。序号为 seq=u+1；表示是在收到了服务器端报文的基础上，将其确认号 ack 值作为本段报文序号的值。确认号为 ack=w+1；表示是在收到了服务器端报文的基础上，将其序号 seq 值加 1 作为本段报文确认号的值。

随后客户端开始在 TIME-WAIT 阶段等待 2MSL。

与“三次挥手”一样，在客户端与服务器端传输的 TCP 报文中，双方的确认号 Ack 和序号 Seq 的值，都是在彼此 Ack 和 Seq 值的基础上进行计算的，这样做保证了 TCP 报文传输的连贯性，一旦出现某一方发出的 TCP 报文丢失，便无法继续"挥手"，以此确保了"四次挥手"的顺利完成。

#### 为什么“握手”三次，“挥手”却要四次

**建立连接时**，被动方服务器端结束 CLOSED 阶段进入“握手”阶段**并不需要任何准备，可以直接返回 SYN 和 ACK 报文，开始建立连接**。（在第二次"握手"过程中，SYN 建立连接报文与 ACK 确认接收报文是在同一次"握手"当中传输的）

**释放连接时**，被动方服务器，突然收到主动方客户端释放连接的请求时**并不能立即释放连接**，因为还有必要的数据需要处理，所以服务器先返回 ACK 确认收到报文，经过 CLOSE-WAIT 阶段**准备好释放连接之后，才能返回 FIN 释放连接报文**。（FIN 释放连接报文与 ACK 确认接收报文是分别由第三次和第二次"挥手"传输的）

#### 为什么客户端在 TIME-WAIT 阶段要等 2MSL

为的是确认服务器端收到了客户端发出的 ACK 确认报文。

> 第三次挥手后，服务器端在 1MSL 内没有收到客户端发出的 ACK 确认报文，就会再次向客户端发出 FIN 报文；所以，如果客户端在 2MSL 内，再次收到了来自服务器端的 FIN 报文，说明服务器端由于各种原因没有接收到客户端发出的 ACK 确认报文。这时，客户端就会再次向服务器端发出 ACK 确认报文，计时器重置，重新开始 2MSL 的计时。否则说明服务器端正常接收了 ACK 确认报文，客户端可以进入 CLOSED 阶段，完成“四次挥手”

#### 参考

[详解 TCP 连接的“ 三次握手 ”与“ 四次挥手 ”](https://baijiahao.baidu.com/s?id=1654225744653405133&wfr=spider&for=pc)

[面试官，不要再问我三次握手和四次挥手](https://zhuanlan.zhihu.com/p/86426969)



## 比较 http、http2、https

## HTTP/0.9

HTTP 的最早版本诞生在 1991 年，它没有 HTTP 头，没有状态码，甚至版本号也没有，是后来才被定为 0.9 来和其他版本区分。

只支持一种方法—— Get，请求只有一行：`GET /hello.html`

响应也只包含 html 文档本身：`<HTML> Hello world </HTML>`

服务器向客户端返回 HTML 格式的字符串。发送完毕后，就关闭 TCP 连接。由于没有状态码和错误代码，如果服务器处理的时候发生错误，只会传回一个特殊的包含问题描述信息的 HTML 文件。这就是最早的 HTTP/0.9 版本。

## HTTP/1.0

1996 年，HTTP/1.0 版本发布，大大丰富了 HTTP 的传输内容，除了文字，还可以发送图片、视频等。

主要有如下特性：

- 请求与响应支持 HTTP 头，增加了状态码，响应对象的一开始是一个响应状态行
- 协议版本信息需要随着请求一起发送，支持 HEAD，POST 方法
- 支持传输 HTML 文件以外其他类型的内容

## HTTP/1.1

在 HTTP/1.0 发布几个月后，HTTP/1.1 就发布了。HTTP/1.1 更多的是作为对 HTTP/1.0 的完善。

但 HTTP/1.0 在 1999 年才开始广泛应用于现在的各大浏览器网络请求中，同时也是当前使用最为广泛的 HTTP 协议。

**主要区别**主要体现在：

### 1.长连接

HTTP1.0 默认是短连接，每次与服务器交互，都需要新开一个连接。

在 HTTP1.1 中默认持久连接：只要没有明确提出端口就一直保持，可以发送多次 HTTP 请求：`Connection: keep-alive`

### 2.分块/断点传输

引入了 `transfer-coding: chunked`（分块传输）的消息头，实现断点续传：实际上就是使用分块传输编码，将实体主体分块传输。

> 请求头 range，它表示了要请求资源的哪个部分。如果服务器相应地返回了所请求的范围的内容，在响应头 Content-Range 中声明返回的这部分对象的偏移值和长度，响应码为 206（Partial Content），可以防止 Cache 将响应误以为是完整的。
>
> 加入了一个新的状态码 100（Continue）。客户端事先发送一个只带头域的请求，如果服务器因为权限拒绝了请求，就回送响应码 401（Unauthorized）；如果服务器接收此请求就回送响应码 100，客户端就可以继续发送带实体的完整请求了。**注意，HTTP/1.0 的客户端不支持 100 响应码。但可以让客户端在请求消息中加入 Expect 头域，并将它的值设置为 100-continue。**

### 3.Host 头域

请求消息和响应消息都支持，表示访问资源所在的主机名，即 URL 中的域名部分。如：m.baidu.com

> 在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个 IP 地址。因此，Host 头的引入就很有必要了。

### 4.缓存处理

在 HTTP1.0 中是使用下面头域来做为缓存判断的标准

- 强缓存：Expires（请求头、响应头中都有）
- 协商缓存：if-modified-since（请求头）、last-modified（响应头）

HTTP1.1 则引入了更多可供选择的缓存头来控制缓存策略。

- 强缓存：cache-control
- 协商缓存：if-none-match（请求头）、Etag（响应头）

### 5.增加 pipeline

HTTP 管线化，在持久连接前提下，将多个 HTTP 请求整批提交的技术，而在传送过程中不需先等待服务端的回应。可大幅缩短页面的加载时间。有一点需要注意的是，只有幂等的请求可以使用 pipeline，如 GET，HEAD 方法。

> 在 HTTP1.0 中，发送一次请求时，需要**等待服务端响应了**才可以继续发送请求。
>
> 在 HTTP1.1 中，发送一次请求时，不需要等待服务端响应了就可以发送请求了，但是回送数据给客户端的时候，客户端还是需要按照**响应的顺序**来一一接收。所以，无论是 HTTP1.0 还是 HTTP1.1 提出的 Pipelining 理论，还是会出现**阻塞**的情况。从专业的名词上说，叫做**队头阻塞**（Head of line blocking）。
>
> 但是 pipeline 仅仅是限于理论的阶段上，这个功能默认还是关闭了的。

### 缺点

#### 无状态

在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，这时无状态就是 http 的缺点。

但与此同时，另外一些应用仅仅只是为了获取一些数据，不需要保存连接上下文信息，无状态反而减少了网络开销，成为了 http 的优点。

##### 解决办法

为了记录状态，引入了 Cookie 技术

#### 明文传输

即协议里的报文（主要指的是头部）不使用二进制数据，而是文本形式。

这当然对于调试提供了便利，但同时也让 HTTP 的报文信息暴露给了外界，给攻击者也提供了便利。`WIFI陷阱` 就是利用 HTTP 明文传输的缺点，诱导你连上热点，然后疯狂抓你所有的流量，从而拿到你的敏感信息。

##### 解决办法

HTTP + TSL = HTTPS

#### 队头阻塞

当 http 开启长连接时，共用一个 TCP 连接，当某个请求时间过长时，其他的请求只能处于阻塞状态，这就是队头阻塞问题。通常我们提到队头阻塞，指的可能是 TCP 协议中的队头阻塞，但是 HTTP1.1 中也有一个类似 TCP 队头阻塞的问题。

1. TCP 的队头阻塞：TCP 要求数据严格按照序号顺序，前一个报文没有收到便不会将后面收到的报文上传给 HTTP
2. HTTP 的队头阻塞：HTTP 管道化要求服务端必须按照请求发送的顺序返回响应，那如果一个响应返回延迟了，那么其后续的响应都会被延迟，直到队头的响应送达。

两者所在的层次不一样。TCP 的队头阻塞是在`数据包`层面，单位是`数据包`，而 HTTP 的队头阻塞是在 `HTTP 请求-响应`层面。

##### 解决办法

1.**并发连接**

一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务（Chrome 中是 6 个）

2.**域名分片**

一个域名可以并发 6 个长连接，那就多分几个域名。

在一个域名下分出多个二级域名出来，而它们最终指向的还是同一个服务器，这样子的话就可以并发处理的任务队列更多。

比如 woc12138.com，可以分出很多二级域名，比如 **Day1.woc12138.com**，**Day2.woc12138.com**，**Day3.woc12138.com**

3.**HTTP2 的多路复用**

> 上面两种方法并没有真正从 HTTP 本身的层面解决问题，只是增加了 TCP 连接，分摊风险而已。而且这么做也有弊端，多条 TCP 连接会竞争**有限的带宽**，让真正优先级高的请求不能优先处理。
>
> 而 HTTP/2 便从 HTTP 协议本身解决了`队头阻塞`问题。注意，这里并不是指的`TCP队头阻塞`，而是`HTTP队头阻塞`

HTTP2 不使用管道化的方式，而是引入了帧、消息和数据流等概念，每个请求/响应被称为消息，每个消息都被拆分成若干个帧进行传输，每个帧都分配一个序号。每个帧在传输是属于一个数据流，而一个连接上可以存在多个流，各个帧在流和连接上独立传输，到达之后在组装成消息，这样就避免了请求/响应阻塞。

## HTTP 2

2015 年 HTTP/2.0 问世。

对于 HTTP/1.x，即使开启了长连接，请求的发送也是串行发送的，在带宽足够的情况下，对带宽的利用率不够，HTTP/2.0 与 HTTP1.1 最重要的区别就是**解决了队头阻塞的**问题。

其中最重要的改动是：

### 1.二进制分帧层

HTTP1.x 的解析是基于文本，解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景很多；二进制则不同，只认 0 和 1 的组合。HTTP2.0 的协议解析采用二进制分帧格式，实现方便且健壮。

> 在应用层（HTTP）与传输层（TCP + TLS）之间增加一个二进制分帧层（Binary Framing），HTTP2.0 会将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中 HTTP1.x 的首部信息会被用 frame 封装到 Headers 帧，而 request body 则用 frame 封装到 Data 帧里面。

![img](https://img-blog.csdnimg.cn/20201015155821574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 2.多路复用 (Multiplexing)

分帧之后，服务器看到的不再是一个个的 HTTP 请求报文，而是一堆乱序的二进制帧，这些帧不分前后关系，也就不会排队等待，就没有了 HTTP 的队头阻塞问题。

通信双方都可以给对方发送二进制帧，这种二进制帧的**双向传输的序列**，也叫做`流`(Stream)。HTTP/2 用`流`来在一个 TCP 连接上来进行多个数据帧的通信，这就是**多路复用**的概念。

> 这里的乱序指的是不同 ID 的 Stream 是乱序的，但同一个 Stream ID 的帧一定是按顺序传输的。二进制帧到达后对方会将 Stream ID 相同的二进制帧组装成完整的**请求报文**和**响应报文**。

![img](https://img-blog.csdnimg.cn/20201015155912174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

### 3.header 压缩

HTTP1.x 的 header 带有大量信息，每次请求 header 基本不怎么变化，每次都要重复发送。HTTP2.0 使用 **HPACK 算法**来压缩需要传输的 header 大小，通讯时在服务器和客户端之间建立哈希表，将用到的字段存放在这张表中，那么在传输的时候对于之前出现过的值，只需要把**索引**（0，1，2，...）传给对方，对方拿到索引查表即可。

### 4.服务端推送

在 HTTP/2.0 中，服务器可以向客户发送请求之外的内容，比如正在请求一个页面时，服务器会把页面相关的 logo，CSS 等文件直接推送到客户端，而不会等到请求来的时候再发送，因为服务器认为客户端会用到这些东西。当客户端再次尝试获取这些资源时就可以直接从缓存中获取到，不用再发请求了。

### 5.数据流优先级

由于请求可以并发发送了，如果出现了浏览器在等待关键的 CSS 或者 JS 文件完成对页面的渲染时，服务器却在专注的发送图片资源的情况时，HTTP/2.0 对数据流可以设置优先值，这个优先值决定了客户端和服务端处理不同的流采用不同的优先级策略。

## HTTPS

HTTP 是 HTTP 的安全版，实际就是在 TCP 层与 HTTP 层之间加入了 SSL/TLS 来为安全保驾护航，主要用到对称加密、非对称加密、证书，等技术进行客户端与服务器的数据加密传输。HTTPS = HTTP + TLS/SSL

- SSL 是安全套接层(secure sockets layer)：在 OSI 七层模型中处于会话层(第 5 层)，1.0、2.0 已废除、3.0 基本废除。
- TLS 是 SSL 的继任者，叫传输层安全(transport layer security)：TLS1.0 = SSL3.1，现在主流的版本是 TLS/1.2，之前的 TLS1.0、TLS1.1 都被认为是不安全的，在不久的将来会被完全淘汰。

### 工作原理

#### 1.对称加密

加密和解密都是用的同一个密钥

> 传输信息的双方都要知道对称密钥，通过密钥加密传输的信息，但是一端生成一个对称密钥，然后通过 HTTP 传输给另一端又是不安全的，可能被中间人拦截获取到这个密钥。使用对称加密的方式，行不通，所以我们需要采用非对称加密。

#### 2.非对称加密

公钥加密的内容，只有私钥可以解开，私钥加密的内容，所有的公钥都可以解开。公钥可以发送给所有客户端，私钥只保存在服务器端，两者成对出现。

> 想要安全的传递信息，A 可以用公钥加密信息传递给 B，B 用私钥解密看到信息的内容。只要 B 的私钥不泄露，信息就算被其他人获取到也无法解密。
>
> 但是，又出现了一个问题：虽然别人不知道私钥是什么，拿不到你**原始传输**的数据，但是可以拿到加密后的数据，他们可以**改掉**某部分的数据再发送给服务器，这样服务器拿到的数据就**不是完整的**了。于是，就出现了**数字签名**来解决被篡改的问题。

#### 3.数字签名

- 验证传输的内容是对方发送的数据（认证）
- 验证发送的数据有没有被篡改过（保证完整性）

> 也可以看做是**非对称加密的手段一种**，就是把公钥私钥的用法反过来，之前是公钥加密、私钥解密，现在是私钥加密、公钥解密。
>
> 1. B 先用摘要算法（常用的有 SHA224、SHA256、SHA384），生成信息的摘要（digest）
>
>    MD5 也是摘要算法，但是不够安全，在 TSL 里已经被禁止使用了。
>
> 2. 然后使用私钥，对这个摘要加密，生成"数字签名"（signature）
>
>    如果不对摘要加密，那么摘要也有可能被篡改。
>
> 3. 将这个签名，和信息一起发给 A
>
> 4. A 收到后用公钥解密数字签名，得到摘要，由此证明，信息确实是 B 发出的。
>
> 5. 再对信息本身使用 Hash 函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明信息未被修改过。
>
> 但是，复杂的情况又出现了：如果 C 将 A 原本有的 B 的公钥换成自己伪造的公钥。这时，A 以为自己拥有的是 B 的公钥，但实际上是 C 的。所以，C 就可以冒充 B，发送信息给 A，然后 A 用伪造的公钥解密比对后并没有出现问题。
>
> 于是，就出现了**CA 认证机构**来确认公钥的真实性。

![img](https://img-blog.csdnimg.cn/20201015155915425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

#### 4.数字证书认证机构（Certificate Authority）

简称 CA，认证机构将证明是**真实的服务器**发送的数据。

每一个使用 HTTPS 的服务器都必须去专门的证书机构注册一个证书，证书中存储了用权威机构私钥加密的公钥。这样客户端用权威机构的公钥解密就可以了。

#### 步骤

![img](https://img-blog.csdnimg.cn/20201015160059792.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

1.A（Client）发起一个 HTTPS 请求，连接 443 端口。这个过程可以理解成是**请求公钥的过程**。

2.B（Server）端收到请求后，用 `CA自己的私有密钥` 对`B公钥 + B各种信息`加密生成数字签名，然后把数字证书（也可以认为是公钥证书，由`B公钥+B各种信息` 和 `加密后生成的数字签名` 组成）发送给 A。（这样子的话，数字证书包含有两个特别重要的信息 👉**B 的公钥+数字签名**）

> CA 对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还要包含序列号、用途、颁发者、有效时间等等，把这些打成一个包再签名。在将签名和完整地证明公钥的各种信息，形成“数字证书”（Certificate）。

3.A 使用 `CA的公钥`（浏览器安装后会自带一些 CA 公钥）对证书中的数字签名进行解密得到了 `B的公钥`，将这个解出来的 B 的公钥与证书中带的 B 的公钥对比判断证书是否有效，继而证明"数字签名"是否真的是 B 发出的。

![img](https://img-blog.csdnimg.cn/20201015160104346.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

> 这样就可以防止第三方冒充服务器：
>
> 首先 B 发的内容，无法被 C 篡改。C 虽然有权威机构的公钥，可以解密获得 B 的公钥，但是因为没有权威机构的私钥，所以解密以后的信息无法加密。C 将没有加密或者错误加密的信息发送给 A，被 A 用权威机构的公钥解密出来的内容，必然无法通过校验。
>
> 但是，如果你一开始请求的就不是真的服务器，而是一个攻击者，此时的他完全有机会进行中间人攻击。我们知道第一次握手的时候服务器会下发用于证明自己身份的证书，这个证书会用预设在设备上的公钥来解密。所以要么是经过认证的证书用权威机构的私钥加密，再用权威机构解密，要么是用非权威机构的私钥加密，然后找不到公钥解密。

如果没有数字签名的话，这样子可以就会有下面情况：

![img](https://img-blog.csdnimg.cn/20201015160110718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

> 如果**只是对网站信息进行第三方机构私钥加密**的话，还是会受到欺骗。
>
> 因为没有认证，所以中间人也向第三方认证机构进行申请，然后拦截后把所有的信息都替换成自己的，客户端仍然可以解密，并且无法判断这是服务器的还是中间人的，最后造成数据泄露。

4.在安全拿到 B 的公钥后，A 随机生成一个**对称密钥**，使用**B 的公钥**加密这个**对称密钥**，发送给 B。

5.B 通过自己的私钥，对信息解密，得到了**对称密钥**，至此，两者都拥有了相同的**对称密钥**。

接下来，就可以通过该对称密钥对传输的信息加密/解密进行传输啦。

- Client 用户使用该**对称密钥**加密明文内容，发送给 Server
- Server 使用该**对称密钥**进行解密消息，得到明文内容。

#### 总结

- 大致流程：客户端拿到服务器的公钥（是正确的），然后客户端随机生成一个**对称加密的秘钥**，使用**该公钥**加密，传输给服务端，服务端再通过解密拿到该**对称秘钥**，后续的所有信息都通过该**对称秘钥**进行加密解密，完成整个 HTTPS 的流程。
- **第三方认证**，最重要的是**数字签名**，避免了获取的公钥是中间人的。

### HTTPS 协议的主要作用

1. **认证**用户和服务器，确保数据发送到正确的客户机和服务器。
2. **加密**数据以防止数据中途被窃取。
3. 维护数据的**完整性**，确保数据在传输过程中不被篡改。

### 与 HTTP 的区别

1.HTTPS 需要 CA 证书，需要花钱买

2.HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，HTTPS 运行在 SSL/TLS 之上，SSL/TLS 运行在 TCP 之上，所有传输的内容都经过加密的。

3.HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。

4.HTTPS 可以有效的防止运营商劫持，解决了防劫持的一个大问题。

## 总结

HTTP/2 新增了很多特性，但是 HTTP 的语法不需要重新学。HTTP/2 完全兼容之前 HTTP 的语法和语义，如**请求头、URI、状态码、头部字段**都没有改变。

![img](https://img-blog.csdnimg.cn/20201015160115325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNTA4ODMy,size_16,color_FFFFFF,t_70#pic_center)

## 参考

[HTTP 的前世今生：一次性搞懂 HTTP、HTTPS、SPDY、HTTP2](https://juejin.im/post/6844903712113360903)

[什么是队头阻塞以及如何解决](https://juejin.im/post/6844903853985366023)

[介绍一个 HTTPS 工作原理](http://poetries1.gitee.io/fe-interview/blog-docs/http/-HTTP相关总结.html#介绍一个https工作原理)

[HTTP2 和 HTTPS 来不来了解一下？](https://juejin.im/post/6844903648850345997)

[计算机网络之 HTTP、HTTPS、HTTP2](https://blog.csdn.net/striveb/article/details/91585050)

[神三元的博客：HTTP/2 有哪些改进？](http://47.98.159.95/my_blog/http/017.html#头部压缩)







# HTTP的缺点以及HTTPS的出现

之前做了一个网站的项目，之前的网站用的都是HTTP协议的，这是一个超文本传输协议，这篇文章不说HTTP协议内部是怎么实现的，我只在我之前的基础上，说一些HTTP的缺点以便引进HTTPS协议（超文本传输安全协议），简单理解，它就是安全的HTTP协议。

HTTP是很轻巧方便的协议。但与此同时，HTTP协议也有很多的缺点：

HTTP协议通信使用明文（未加密的报文），不对传输内容进行加密，如果使用fiddler等抓包工具可以很轻松地截取到HTTP的请求与响应报文（事实上我在做网站的时候经常用fiddler抓包来查看报文内容）
HTTP不会验证通信双方的身份，因此有可能出现别的人伪装成对方来和你通信，即通信双方很可能是伪装的，比如我访问百度首页，我并不知道这个响应就是百度返回给我的，也可能是别的人伪装成百度来和我通信
HTTP无法证明报文的完整性，有可能报文被截取以后被篡改了再发给我，这样我得到的就是被篡改了的报文。
以上三个缺点，可以简要地归结为如下三点：易被窃听，无身份验证，易被篡改。

事实上，不仅仅是HTTP协议，几乎所有的不加密的协议都会出现此类问题。

 

TCP/IP是可以被窃听的网络
按照TCP/IP协议的工作机制，通信内容在所有的通信线路上都有可能遭到窥视。可以这样理解，在互联网通信时，在通信线路上的所有网络设备等都不是个人私有物，所以很容易被他人所窃听。

所谓的数据加密，其实只是对我们的报文内容进行一个加密，但是我们加密以后的内容还是可以被窃听，但是窃听者不知道怎么对这些加密了的报文进行解密，这在一定程度上起到了数据安全的作用。

加密处理防止数据被窃听
通信加密

HTTP没有加密机制，但可以通过和SSL（Secure Socket Layer，安全套接层）或TLS（Transport Layer Security，安全传输层协议）的组合使用，加密HTTP的通信内容
在用SSL建立安全通信线路之后，就可以在这条线路上进行HTTP通信了
内容加密

对HTTP传输内容本身进行加密，这就需要发送方对HTTP报文加密以后再发送请求。
这就要求通信双方使用共同的一套加密和解密机制
但是注意，由于这种加密方式不同于SSL或TLS将整个通信线路加密处理，所以内容仍有被篡改的风险（比如，第三方截取到了报文，并对加密信息做了一些改变，可能是乱改，因为它也不知道加密和解密的机制，但是这样也破坏了接收方收到的信息，按原来的解密方式解密以后，可能就是已经不同于应有内容的数据）


不验证通信双方的身份就容易发生伪装
HTTP中的请求和响应不会对通信双方的身份进行确认，可能客户端浏览器实际访问的服务器就不是URL真正指定的服务器，服务器返回给的客户端浏览器的响应不是真正发起请求的客户端浏览器

HTTP服务器可以接收任何请求，只要谁发来了一个请求就会返回一个响应。

由于没有身份验证的问题，并且对请求来者不拒，于是就会出现下面几种情况

接收到请求的服务器可能是伪装的服务器
接收到响应的客户端可能是伪装的客户端
无法确定通信双方是否存在具备访问权限（因为某些内容，只想发送给特定的用户，普通用户可能没有权限访问）
即使是无意义的请求也会来者不拒，无法阻止海量请求下的DOS攻击
查明对方证书来验证通信双方身份
虽然HTTP本身没有验证身份的机制，但是SSL有一种证书手段，可以用来进行身份验证。

证书是由双方都认可的第三方机构颁发的，用来证明服务器和客户端都是实际存在的（可以理解为日常生活中的担保）。而对于证书，从技术上来说，伪造证书是非常困难的事。所以只要能够确认通信方持有的证书，即可判断通信方的真实意图。

客户端在建立连接的时候，会先验证一下服务器的证书，用来确认访问的即是这个服务器。而服务器持有第三方发给的证书，于是将此证书返回给客户端，于是客户端知道，我要访问的就是这个服务器，于是身份验证就好了。

对于支付宝之类的涉及个人财产即隐私的服务器，尤其需要身份验证，否则用户数据一旦泄露后果不堪设想。

同时，客户端也持有证书，这样即可做到个人信息的确认，服务器就知道我到底访问的是不是这个人了。

接收到的内容可能会被篡改
HTTP无法保证内容的完整性，即无法保证客户端接收到的响应和服务器发出的响应的内容是一样的，在传输过程中可能被篡改。

比如要从网站上下载内容，HTTP无法确定客户端下载到的内容就是服务器上存放的那个文件，即使内容被改变，客户端也是察觉不到的。这就是中间人攻击，由中间人截取报文并篡改。

如何防止篡改
之前在说到加密的时候我们说到，可以通过一些加密手段来对内容进行加密，其中常用的方法有MD5和SHA1等散列值校验的方法，以及用来确认文件的数字签名方法。

提供文件下载服务的网站也会提供相应的数字签名，以及MD5算法生成的散列值。但是不论哪种方法，都需要操作客户端的用户本人亲自检查验证下载的文件是否就是服务器上的文件，浏览器无法帮助用户检查。

但即使用了上面的方法，也无法保证数据不被篡改，上面说过了，因为可能MD5本身被改了的话，还是会发生篡改的问题。

 

为了有效防止上面说到的 易被窃听，无身份验证，易被篡改这三个问题，就引入了HTTPS。

HTTPS就是HTTP+SSL协议，HTTP协议本身无法解决这些问题，就得依靠别的协议。而SSL协议做的事情，其实就是数据加密，身份认证，保证数据完整性不被篡改。因此之前所说的HTTP的缺点，HTTPS就可以很好的解决。

下一篇文章我们再来探讨HTTPS协议

上一篇文章说到HTTP的缺点，并引入了HTTPS，这篇文章来看看HTTPS通信的原理是怎样的。（其实抛去HTTP协议，HTTPS就剩下一个Secure安全协议，可以是SSL或是TLS，我们主要探讨的是这种安全机制是怎么实现的）

因为HTTP有以下三个缺点：无加密，无身份认证，无完整性保护，因此所谓的HTTPS，它其实就是HTTP+加密+身份认证+完整性保护。HTTPS并不是一种新的协议，在通信接口使用了SSL和TLS协议而已。HTTP通常直接和TCP通信，而HTTPS中HTTP先和SSL通信，再由SSL和TCP进行通信。模型如下



需要注意的是，SSL协议并不是一个应用层协议，它是介于应用层和传输层协议之间的一个安全协议。

对称密钥加密
SSL采用对称密钥进行加密，所谓的对称密钥，就是加密和解密都用同一个密钥，因此也叫做共享密钥加密。

但是这种方法也有一个弊端，一旦密钥被第三方获得了，就可以对数据进行解密并窃取，因此这并不是一个完全安全的方法。事实上，如果加密解密方法十分简单，是很容易被第三方截取的。

所以这种方法的缺陷就在于，如果一方不发送密钥，对方就无法利用密钥解密。另外，如果发送了密钥，但是密钥被第三方截取了，数据就容易被窃取。因此，需要一种方式，能够保证该密钥能够确保送到对方手中并且还不能够让第三方截取。 

非对称密钥加密
SSL还采用了一种技术就是非对称密钥加密，所谓的非对称密钥，就是这是一对密钥，一个是私钥，一个是公钥。私钥不能让其他任何人知道，而公钥可以随意发布，任何人都可以获得到，因此这种加密方式也叫公开密钥加密。

它的原理是这样的：

客户端向服务器发起请求，服务器创建一对非对称密钥，将公有私钥返回给可客户端，自己保留着这个私钥而不发送。
客户端收到了来自服务器的公钥，于是将自己的数据通过公钥加密，并返回给服务器
服务器接收到了客户端的数据，因为使用自己发送的公钥加密的，因此用自己的私钥对其进行解密，拿到数据
即使第三方拿到了加密后的数据，因为没有私钥，因此也无法获取到真实的数据。假如想要破解这个解密方式，是十分困难的。
HTTPS使用两种加密方式的混合加密
对称密钥加密方式的优缺点：

优点：处理速度快
缺点：但是容易被第三方盗取
非对称密钥加密方式的优缺点：

优点：更加安全，不容易被盗取
缺点：处理效率相比对称密钥加密要慢，如果在通信时用这种方式加密，效率很低
于是HTTPS采用了两者的优点，使用了混合加密的方式

使用非对称密钥加密的方式安全地交换再稍后对称密钥加密中要使用的密钥
确保交换的密钥是安全的之后，放弃非对称密钥加密，使用对称密钥加密来进行通信，保证传输效率
HTTPS使用的各种证书
证明公开密钥正确性的数字证书

客户端无法判断自己收到的服务器的公钥是否是正确的，是否在服务器发送给客户端的过程中被第三方篡改了。

为了解决上面的问题，服务器可以使用由数字证书认证机构（CA）颁发的证书，这种机构是客户端和服务器双方的第三方机构。服务器获取证书的流程如下：

服务器运营人员向CA提出公开密钥的申请
CA在判明申请者的身份之后，会对已申请的公开密钥做数字签名，然后将这个签名的公开密钥和放入公钥证书分配给服务器公司
服务器会把这个由CA颁发的公钥证书以及公开密钥发送给客户端，以此来和客户端进行通信
接收到证书的客户端可以使用公开密钥对证书上的签名进行认证，一旦认证通过，客户端就可以知道认证服务器公开密钥的是真实有效的CA，并且服务器的公开密钥是值得信赖的
CA的公开密钥已经事先植入到浏览器中，客户端通过CA的公开密钥向CA认证服务器的公钥证书上的数字签名的真实性。

 

证明企业真实性的EV SSL证书

该证书用来验证服务器背后运营的企业的合法性

 

用以确认客户端的客户端证书

该证书用来向服务器证明，与之通信的客户单是预料之内的客户端。

想要获取证书 时，用户得自行安装客户端证书，但是客户端证书是要付费买的。

因为成本比较大，因此只有某些特定的业务，如网上银行等，就需要使用客户端证书。

 

HTTPS是怎么解决HTTP协议的三大缺点的？
防监听：采用对称加密对数据进行加密，采用非对称加密对对称加密的密钥进行加密
防伪装：通信双方携带证书，证书有第三方颁发，很难伪造
防篡改：采用摘要算法（MD5或是SHA-1），同样的数据由同样的摘要，而只要有一点不同的数据，它的摘要往往不同，只要数据做了篡改，就会被感知到。

HTTPS的通信流程
客户端向服务器发起SSL通信，报文中包含客户端支持的SSL的指定版本，加密组件列表（所使用的加密算法及密钥长度）
服务器的响应报文中，包含SSL版本以及加密组件，服务器的加密组件内容是从客户端发来的加密组件列表中筛选出来的，服务器还会发一个公开密钥并且带有公钥证书
客户端拿到服务器的公开密钥，并验证其公钥证书（使用浏览器中已经植入的CA公开密钥）
如果验证成功，客户端生成一个Pre-master secret随机密码串，这个随机密码串其实就是之后通信要用的对称密钥，并用服务器的公开密钥进行加密，发送给服务器，以此通知服务器，之后的报文都会通过这个对称密钥来加密
同时，客户端用约定好的hash算法计算握手消息，然后用生成的密钥进行加密，一起发送给服务器
服务器收到客户端发来的的公开密钥加密的对称密钥，用自己的私钥对其解密拿到对称密钥，再用对称密钥解析握手消息，验证hash值是否与客户端发来的一致。如果一致，则通知客户端SSL握手成功
之后的数据交互都是HTTP通信（当然通信会获得SSL保护），且数据都是通过对称密钥来加密（这个密钥不会每次都发，在握手的过程中，服务器已经知道了这个对称密钥，再有数据来时，服务器知道这些数据就是通过对称密钥加密的，于是就直接解密了）
HTTP与HTTPS的区别
HTTPS更加安全，因为它有加密，身份认证，验证数据完整性等环节
HTTPS需要申请证书，要付费（要钱！一年大概600元）
加密通信需要消耗更多的cpu和内存资源，如果每次通信都加密，会消耗很多的资源，当访问量很多的那些网站在进行加密处理时，它们所承担着的负载就很多了，这个时候就需要服务器端实现负载均衡。（有专用的https加解密硬件服务器）
使用端口不同，HTTP使用的是80端口，HTTPS使用的是443端口
所在层次不同，HTTP运行在TCP之上，HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS运行在TCP之上


以上内容大多是总结《图解HTTP》一书，用自己的话理解得来。



# [神三元掘金文章](https://juejin.cn/post/6844904100035821575#heading-98)

![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/23/17104ea1fdee5669~tplv-t2oaga2asx-watermark.awebp)

## 001. HTTP 报文结构是怎样的？

对于 TCP 而言，在传输的时候分为两个部分:**TCP头**和**数据部分**。

而 HTTP 类似，也是`header + body`的结构，具体而言:

```
起始行 + 头部 + 空行 + 实体
复制代码
```

由于 http `请求报文`和`响应报文`是有一定区别，因此我们分开介绍。

### 起始行

对于请求报文来说，起始行类似下面这样:

```
GET /home HTTP/1.1
复制代码
```

也就是**方法 + 路径 + http版本**。

对于响应报文来说，起始行一般张这个样:

```
HTTP/1.1 200 OK
复制代码
```

响应报文的起始行也叫做`状态行`。由**http版本、状态码和原因**三部分组成。

值得注意的是，在起始行中，每两个部分之间用**空格**隔开，最后一个部分后面应该接一个**换行**，严格遵循`ABNF`语法规范。

### 头部

展示一下请求头和响应头在报文中的位置:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd6012e2fc88~tplv-t2oaga2asx-watermark.awebp)





![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd62af8538e4~tplv-t2oaga2asx-watermark.awebp)



不管是请求头还是响应头，其中的字段是相当多的，而且牵扯到`http`非常多的特性，这里就不一一列举的，重点看看这些头部字段的格式：

- 1. 字段名不区分大小写
- 1. 字段名不允许出现空格，不可以出现下划线`_`
- 1. 字段名后面必须**紧接着`:`**

### 空行

很重要，用来区分开`头部`和`实体`。

问: 如果说在头部中间故意加一个空行会怎么样？

那么空行后的内容全部被视为实体。

### 实体

就是具体的数据了，也就是`body`部分。请求报文对应`请求体`, 响应报文对应`响应体`。

## 002. 如何理解 HTTP 的请求方法？

### 有哪些请求方法？

`http/1.1`规定了以下请求方法(注意，都是大写):

- GET: 通常用来获取资源
- HEAD: 获取资源的元信息
- POST: 提交数据，即上传数据
- PUT: 修改数据
- DELETE: 删除资源(几乎用不到)
- CONNECT: 建立连接隧道，用于代理服务器
- OPTIONS: 列出可对资源实行的请求方法，用来跨域请求
- TRACE: 追踪请求-响应的传输路径

### GET 和 POST 有什么区别？

首先最直观的是语义上的区别。

而后又有这样一些具体的差别:

- 从**缓存**的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
- 从**编码**的角度，GET 只能进行 URL 编码，只能接收 ASCII 字符，而 POST 没有限制。
- 从**参数**的角度，GET 一般放在 URL 中，因此不安全，POST 放在请求体中，更适合传输敏感信息。
- 从**幂等性**的角度，`GET`是**幂等**的，而`POST`不是。(`幂等`表示执行相同的操作，结果也是相同的)
- 从**TCP**的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分。(**火狐**浏览器除外，它的 POST 请求只发一个 TCP 包)

## 003: 如何理解 URI？

**URI**, 全称为(Uniform Resource Identifier), 也就是**统一资源标识符**，它的作用很简单，就是区分互联网上不同的资源。

但是，它并不是我们常说的`网址`, 网址指的是`URL`, 实际上`URI`包含了`URN`和`URL`两个部分，由于 URL 过于普及，就默认将 URI 视为 URL 了。

### URI 的结构

URI 真正最完整的结构是这样的。



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd677629b70d~tplv-t2oaga2asx-watermark.awebp)



可能你会有疑问，好像跟平时见到的不太一样啊！先别急，我们来一一拆解。

**scheme** 表示协议名，比如`http`, `https`, `file`等等。后面必须和`://`连在一起。

**user:passwd**@ 表示登录主机时的用户信息，不过很不安全，不推荐使用，也不常用。

**host:port**表示主机名和端口。

**path**表示请求路径，标记资源所在位置。

**query**表示查询参数，为`key=val`这种形式，多个键值对之间用`&`隔开。

**fragment**表示 URI 所定位的资源内的一个**锚点**，浏览器可以根据这个锚点跳转到对应的位置。

举个例子:

```
https://www.baidu.com/s?wd=HTTP&rsv_spt=1
复制代码
```

这个 URI 中，`https`即`scheme`部分，`www.baidu.com`为`host:port`部分（注意，http 和 https 的默认端口分别为80、443），`/s`为`path`部分，而`wd=HTTP&rsv_spt=1`就是`query`部分。

### URI 编码

URI 只能使用`ASCII`, ASCII 之外的字符是不支持显示的，而且还有一部分符号是界定符，如果不加以处理就会导致解析出错。

因此，URI 引入了`编码`机制，将所有**非 ASCII 码字符**和**界定符**转为十六进制字节值，然后在前面加个`%`。

如，空格被转义成了`%20`，**三元**被转义成了`%E4%B8%89%E5%85%83`。

## 004: 如何理解 HTTP 状态码？

RFC 规定 HTTP 的状态码为**三位数**，被分为五类:

- **1xx**: 表示目前是协议处理的中间状态，还需要后续操作。
- **2xx**: 表示成功状态。
- **3xx**: 重定向状态，资源位置发生变动，需要重新请求。
- **4xx**: 请求报文有误。
- **5xx**: 服务器端发生错误。

接下来就一一分析这里面具体的状态码。

### 1xx

**101 Switching Protocols**。在`HTTP`升级为`WebSocket`的时候，如果服务器同意变更，就会发送状态码 101。

### 2xx

**200 OK**是见得最多的成功状态码。通常在响应体中放有数据。

**204 No Content**含义与 200 相同，但响应头后没有 body 数据。

**206 Partial Content**顾名思义，表示部分内容，它的使用场景为 HTTP 分块下载和断点续传，当然也会带上相应的响应头字段`Content-Range`。

### 3xx

**301 Moved Permanently**即永久重定向，对应着**302 Found**，即临时重定向。

比如你的网站从 HTTP 升级到了 HTTPS 了，以前的站点再也不用了，应当返回`301`，这个时候浏览器默认会做缓存优化，在第二次访问的时候自动访问重定向的那个地址。

而如果只是暂时不可用，那么直接返回`302`即可，和`301`不同的是，浏览器并不会做缓存优化。

**304 Not Modified**: 当协商缓存命中时会返回这个状态码。详见[浏览器缓存](https://link.juejin.cn?target=http%3A%2F%2F47.98.159.95%2Fmy_blog%2Fperform%2F001.html)

### 4xx

**400 Bad Request**: 开发者经常看到一头雾水，只是笼统地提示了一下错误，并不知道哪里出错了。

**403 Forbidden**: 这实际上并不是请求报文出错，而是服务器禁止访问，原因有很多，比如法律禁止、信息敏感。

**404 Not Found**: 资源未找到，表示没在服务器上找到相应的资源。

**405 Method Not Allowed**: 请求方法不被服务器端允许。

**406 Not Acceptable**: 资源无法满足客户端的条件。

**408 Request Timeout**: 服务器等待了太长时间。

**409 Conflict**: 多个请求发生了冲突。

**413 Request Entity Too Large**: 请求体的数据过大。

**414 Request-URI Too Long**: 请求行里的 URI 太大。

**429 Too Many Request**: 客户端发送的请求过多。

**431 Request Header Fields Too Large**请求头的字段内容太大。

### 5xx

**500 Internal Server Error**: 仅仅告诉你服务器出错了，出了啥错咱也不知道。

**501 Not Implemented**: 表示客户端请求的功能还不支持。

**502 Bad Gateway**: 服务器自身是正常的，但访问的时候出错了，啥错误咱也不知道。

**503 Service Unavailable**: 表示服务器当前很忙，暂时无法响应服务。

## 005: 简要概括一下 HTTP 的特点？HTTP 有哪些缺点？

### HTTP 特点

HTTP 的特点概括如下:

1. 灵活可扩展，主要体现在两个方面。一个是语义上的自由，只规定了基本格式，比如空格分隔单词，换行分隔字段，其他的各个部分都没有严格的语法限制。另一个是传输形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便。
2. 可靠传输。HTTP 基于 TCP/IP，因此把这一特性继承了下来。这属于 TCP 的特性，不具体介绍了。
3. 请求-应答。也就是`一发一收`、`有来有回`， 当然这个请求方和应答方不单单指客户端和服务器之间，如果某台服务器作为代理来连接后端的服务端，那么这台服务器也会扮演**请求方**的角色。
4. 无状态。这里的状态是指**通信过程的上下文信息**，而每次 http 请求都是独立、无关的，默认不需要保留状态信息。

### HTTP 缺点

#### 无状态

所谓的优点和缺点还是要分场景来看的，对于 HTTP 而言，最具争议的地方在于它的**无状态**。

在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，那么这时候无状态就是 http 的缺点了。

但与此同时，另外一些应用仅仅只是为了获取一些数据，不需要保存连接上下文信息，无状态反而减少了网络开销，成为了 http 的优点。

#### 明文传输

即协议里的报文(主要指的是头部)不使用二进制数据，而是文本形式。

这当然对于调试提供了便利，但同时也让 HTTP 的报文信息暴露给了外界，给攻击者也提供了便利。`WIFI陷阱`就是利用 HTTP 明文传输的缺点，诱导你连上热点，然后疯狂抓你所有的流量，从而拿到你的敏感信息。

#### 队头阻塞问题

当 http 开启长连接时，共用一个 TCP 连接，同一时刻只能处理一个请求，那么当前请求耗时过长的情况下，其它的请求只能处于阻塞状态，也就是著名的**队头阻塞**问题。接下来会有一小节讨论这个问题。

## 006: 对 Accept 系列字段了解多少？

对于`Accept`系列字段的介绍分为四个部分: **数据格式**、**压缩方式**、**支持语言**和**字符集**。

### 数据格式

上一节谈到 HTTP 灵活的特性，它支持非常多的数据格式，那么这么多格式的数据一起到达客户端，客户端怎么知道它的格式呢？

当然，最低效的方式是直接猜，有没有更好的方式呢？直接指定可以吗？

答案是肯定的。不过首先需要介绍一个标准——**MIME**(Multipurpose Internet Mail Extensions, **多用途互联网邮件扩展**)。它首先用在电子邮件系统中，让邮件可以发任意类型的数据，这对于 HTTP 来说也是通用的。

因此，HTTP 从**MIME type**取了一部分来标记报文 body 部分的数据类型，这些类型体现在`Content-Type`这个字段，当然这是针对于发送端而言，接收端想要收到特定类型的数据，也可以用`Accept`字段。

具体而言，这两个字段的取值可以分为下面几类:

- text： text/html, text/plain, text/css 等
- image: image/gif, image/jpeg, image/png 等
- audio/video: audio/mpeg, video/mp4 等
- application: application/json, application/javascript, application/pdf, application/octet-stream

### 压缩方式

当然一般这些数据都是会进行编码压缩的，采取什么样的压缩方式就体现在了发送方的`Content-Encoding`字段上， 同样的，接收什么样的压缩方式体现在了接受方的`Accept-Encoding`字段上。这个字段的取值有下面几种：

- gzip: 当今最流行的压缩格式
- deflate: 另外一种著名的压缩格式
- br: 一种专门为 HTTP 发明的压缩算法

```
// 发送端
Content-Encoding: gzip
// 接收端
Accept-Encoding: gzip
复制代码
```

### 支持语言

对于发送方而言，还有一个`Content-Language`字段，在需要实现国际化的方案当中，可以用来指定支持的语言，在接受方对应的字段为`Accept-Language`。如:

```
// 发送端
Content-Language: zh-CN, zh, en
// 接收端
Accept-Language: zh-CN, zh, en
复制代码
```

### 字符集

最后是一个比较特殊的字段, 在接收端对应为`Accept-Charset`，指定可以接受的字符集，而在发送端并没有对应的`Content-Charset`, 而是直接放在了`Content-Type`中，以**charset**属性指定。如:

```
// 发送端
Content-Type: text/html; charset=utf-8
// 接收端
Accept-Charset: charset=utf-8
复制代码
```

最后以一张图来总结一下吧:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd6bb6d09c2d~tplv-t2oaga2asx-watermark.awebp)



## 007: 对于定长和不定长的数据，HTTP 是怎么传输的？

### 定长包体

对于定长包体而言，发送端在传输的时候一般会带上 `Content-Length`, 来指明包体的长度。

我们用一个`nodejs`服务器来模拟一下:

```
const http = require('http');

const server = http.createServer();

server.on('request', (req, res) => {
  if(req.url === '/') {
    res.setHeader('Content-Type', 'text/plain');
    res.setHeader('Content-Length', 10);
    res.write("helloworld");
  }
})

server.listen(8081, () => {
  console.log("成功启动");
})
复制代码
```

启动后访问: **localhost:8081**。

浏览器中显示如下:

```
helloworld
复制代码
```

这是长度正确的情况，那不正确的情况是如何处理的呢？

我们试着把这个长度设置的小一些:

```
res.setHeader('Content-Length', 8);
复制代码
```

重启服务，再次访问，现在浏览器中内容如下:

```
hellowor
复制代码
```

那后面的`ld`哪里去了呢？实际上在 http 的响应体中直接被截去了。

然后我们试着将这个长度设置得大一些:

```
res.setHeader('Content-Length', 12);
复制代码
```

此时浏览器显示如下:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd6f598bea62~tplv-t2oaga2asx-watermark.awebp)



直接无法显示了。可以看到`Content-Length`对于 http 传输过程起到了十分关键的作用，如果设置不当可以直接导致传输失败。

### 不定长包体

上述是针对于`定长包体`，那么对于`不定长包体`而言是如何传输的呢？

这里就必须介绍另外一个 http 头部字段了:

```
Transfer-Encoding: chunked
复制代码
```

表示分块传输数据，设置这个字段后会自动产生两个效果:

- Content-Length 字段会被忽略
- 基于长连接持续推送动态内容

我们依然以一个实际的例子来模拟分块传输，nodejs 程序如下:

```
const http = require('http');

const server = http.createServer();

server.on('request', (req, res) => {
  if(req.url === '/') {
    res.setHeader('Content-Type', 'text/html; charset=utf8');
    res.setHeader('Content-Length', 10);
    res.setHeader('Transfer-Encoding', 'chunked');
    res.write("<p>来啦</p>");
    setTimeout(() => {
      res.write("第一次传输<br/>");
    }, 1000);
    setTimeout(() => {
      res.write("第二次传输");
      res.end()
    }, 2000);
  }
})

server.listen(8009, () => {
  console.log("成功启动");
})
复制代码
```

访问效果入下:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd728ba3840d~tplv-t2oaga2asx-watermark.awebp)



用 telnet 抓到的响应如下:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd78332368a0~tplv-t2oaga2asx-watermark.awebp)



注意，`Connection: keep-alive`及之前的为响应行和响应头，后面的内容为响应体，这两部分用换行符隔开。

响应体的结构比较有意思，如下所示:

```
chunk长度(16进制的数)
第一个chunk的内容
chunk长度(16进制的数)
第二个chunk的内容
......
0

复制代码
```

最后是留有有一个`空行`的，这一点请大家注意。

以上便是 http 对于**定长数据**和**不定长数据**的传输方式。

## 008: HTTP 如何处理大文件的传输？

对于几百 M 甚至上 G 的大文件来说，如果要一口气全部传输过来显然是不现实的，会有大量的等待时间，严重影响用户体验。因此，HTTP 针对这一场景，采取了`范围请求`的解决方案，允许客户端仅仅请求一个资源的一部分。

### 如何支持

当然，前提是服务器要支持**范围请求**，要支持这个功能，就必须加上这样一个响应头:

```
Accept-Ranges: none
复制代码
```

用来告知客户端这边是支持范围请求的。

### Range 字段拆解

而对于客户端而言，它需要指定请求哪一部分，通过`Range`这个请求头字段确定，格式为`bytes=x-y`。接下来就来讨论一下这个 Range 的书写格式:

- **0-499**表示从开始到第 499 个字节。
- **500**- 表示从第 500 字节到文件终点。
- **-100**表示文件的最后100个字节。

服务器收到请求之后，首先验证范围**是否合法**，如果越界了那么返回`416`错误码，否则读取相应片段，返回`206`状态码。

同时，服务器需要添加`Content-Range`字段，这个字段的格式根据请求头中`Range`字段的不同而有所差异。

具体来说，请求`单段数据`和请求`多段数据`，响应头是不一样的。

举个例子:

```
// 单段数据
Range: bytes=0-9
// 多段数据
Range: bytes=0-9, 30-39

复制代码
```

接下来我们就分别来讨论着两种情况。

### 单段数据

对于`单段数据`的请求，返回的响应如下:

```
HTTP/1.1 206 Partial Content
Content-Length: 10
Accept-Ranges: bytes
Content-Range: bytes 0-9/100

i am xxxxx
复制代码
```

值得注意的是`Content-Range`字段，`0-9`表示请求的返回，`100`表示资源的总大小，很好理解。

### 多段数据

接下来我们看看多段请求的情况。得到的响应会是下面这个形式:

```
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000010101
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes


--00000010101
Content-Type: text/plain
Content-Range: bytes 0-9/96

i am xxxxx
--00000010101
Content-Type: text/plain
Content-Range: bytes 20-29/96

eex jspy e
--00000010101--
复制代码
```

这个时候出现了一个非常关键的字段`Content-Type: multipart/byteranges;boundary=00000010101`，它代表了信息量是这样的:

- 请求一定是多段数据请求
- 响应体中的分隔符是 00000010101

因此，在响应体中各段数据之间会由这里指定的分隔符分开，而且在最后的分隔末尾添上`--`表示结束。

以上就是 http 针对大文件传输所采用的手段。

## 009: HTTP 中如何处理表单数据的提交？

在 http 中，有两种主要的表单提交的方式，体现在两种不同的`Content-Type`取值:

- application/x-www-form-urlencoded
- multipart/form-data

由于表单提交一般是`POST`请求，很少考虑`GET`，因此这里我们将默认提交的数据放在请求体中。

### application/x-www-form-urlencoded

对于`application/x-www-form-urlencoded`格式的表单内容，有以下特点:

- 其中的数据会被编码成以`&`分隔的键值对
- 字符以**URL编码方式**编码。

如：

```
// 转换过程: {a: 1, b: 2} -> a=1&b=2 -> 如下(最终形式)
"a%3D1%26b%3D2"
复制代码
```

### multipart/form-data

对于`multipart/form-data`而言:

- 请求头中的`Content-Type`字段会包含`boundary`，且`boundary`的值有浏览器默认指定。例: `Content-Type: multipart/form-data;boundary=----WebkitFormBoundaryRRJKeWfHPGrS4LKe`。
- 数据会分为多个部分，每两个部分之间通过分隔符来分隔，每部分表述均有 HTTP 头部描述子包体，如`Content-Type`，在最后的分隔符会加上`--`表示结束。

相应的`请求体`是下面这样:

```
Content-Disposition: form-data;name="data1";
Content-Type: text/plain
data1
----WebkitFormBoundaryRRJKeWfHPGrS4LKe
Content-Disposition: form-data;name="data2";
Content-Type: text/plain
data2
----WebkitFormBoundaryRRJKeWfHPGrS4LKe--
复制代码
```

### 小结

值得一提的是，`multipart/form-data` 格式最大的特点在于:**每一个表单元素都是独立的资源表述**。另外，你可能在写业务的过程中，并没有注意到其中还有`boundary`的存在，如果你打开抓包工具，确实可以看到不同的表单元素被拆分开了，之所以在平时感觉不到，是以为浏览器和 HTTP 给你封装了这一系列操作。

而且，在实际的场景中，对于图片等文件的上传，基本采用`multipart/form-data`而不用`application/x-www-form-urlencoded`，因为没有必要做 URL 编码，带来巨大耗时的同时也占用了更多的空间。

## 010: HTTP1.1 如何解决 HTTP 的队头阻塞问题？

### 什么是 HTTP 队头阻塞？

从前面的小节可以知道，HTTP 传输是基于`请求-应答`的模式进行的，报文必须是一发一收，但值得注意的是，里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。这就是著名的`HTTP队头阻塞`问题。

### 并发连接

对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务。在RFC2616规定过客户端最多并发 2 个连接，不过事实上在现在的浏览器标准中，这个上限要多很多，Chrome 中是 6 个。

但其实，即使是提高了并发连接，还是不能满足人们对性能的需求。

### 域名分片

一个域名不是可以并发 6 个长连接吗？那我就多分几个域名。

比如 content1.sanyuan.com 、content2.sanyuan.com。

这样一个`sanyuan.com`域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，能够并发的长连接数更多了，事实上也更好地解决了队头阻塞的问题。

## 011: 对 Cookie 了解多少？

### Cookie 简介

前面说到了 HTTP 是一个无状态的协议，每次 http 请求都是独立、无关的，默认不需要保留状态信息。但有时候需要保存一些状态，怎么办呢？

HTTP 为此引入了 Cookie。Cookie 本质上就是浏览器里面存储的一个很小的文本文件，内部以键值对的方式来存储(在chrome开发者面板的Application这一栏可以看到)。向同一个域名下发送请求，都会携带相同的 Cookie，服务器拿到 Cookie 进行解析，便能拿到客户端的状态。而服务端可以通过响应头中的`Set-Cookie`字段来对客户端写入`Cookie`。举例如下:

```
// 请求头
Cookie: a=xxx;b=xxx
// 响应头
Set-Cookie: a=xxx
set-Cookie: b=xxx
复制代码
```

### Cookie 属性

#### 生存周期

Cookie 的有效期可以通过**Expires**和**Max-Age**两个属性来设置。

- **Expires**即`过期时间`
- **Max-Age**用的是一段时间间隔，单位是秒，从浏览器收到报文开始计算。

若 Cookie 过期，则这个 Cookie 会被删除，并不会发送给服务端。

#### 作用域

关于作用域也有两个属性: **Domain**和**path**, 给 **Cookie** 绑定了域名和路径，在发送请求之前，发现域名或者路径和这两个属性不匹配，那么就不会带上 Cookie。值得注意的是，对于路径来说，`/`表示域名下的任意路径都允许使用 Cookie。

#### 安全相关

如果带上`Secure`，说明只能通过 HTTPS 传输 cookie。

如果 cookie 字段带上`HttpOnly`，那么说明只能通过 HTTP 协议传输，不能通过 JS 访问，这也是预防 XSS 攻击的重要手段。

相应的，对于 CSRF 攻击的预防，也有`SameSite`属性。

`SameSite`可以设置为三个值，`Strict`、`Lax`和`None`。

**a.** 在`Strict`模式下，浏览器完全禁止第三方请求携带Cookie。比如请求`sanyuan.com`网站只能在`sanyuan.com`域名当中请求才能携带 Cookie，在其他网站请求都不能。

**b.** 在`Lax`模式，就宽松一点了，但是只能在 `get 方法提交表单`况或者`a 标签发送 get 请求`的情况下可以携带 Cookie，其他情况均不能。

**c.** 在`None`模式下，也就是默认模式，请求会自动携带上 Cookie。

### Cookie 的缺点

1. 容量缺陷。Cookie 的体积上限只有`4KB`，只能用来存储少量的信息。
2. 性能缺陷。Cookie 紧跟域名，不管域名下面的某一个地址需不需要这个 Cookie ，请求都会携带上完整的 Cookie，这样随着请求数的增多，其实会造成巨大的性能浪费的，因为请求携带了很多不必要的内容。但可以通过`Domain`和`Path`指定**作用域**来解决。
3. 安全缺陷。由于 Cookie 以纯文本的形式在浏览器和服务器中传递，很容易被非法用户截获，然后进行一系列的篡改，在 Cookie 的有效期内重新发送给服务器，这是相当危险的。另外，在`HttpOnly`为 false 的情况下，Cookie 信息能直接通过 JS 脚本来读取。

## 012: 如何理解 HTTP 代理？

我们知道在 HTTP 是基于`请求-响应`模型的协议，一般由客户端发请求，服务器来进行响应。

当然，也有特殊情况，就是代理服务器的情况。引入代理之后，作为代理的服务器相当于一个中间人的角色，对于客户端而言，表现为服务器进行响应；而对于源服务器，表现为客户端发起请求，具有**双重身份**。

那代理服务器到底是用来做什么的呢？

### 功能

1. **负载均衡**。客户端的请求只会先到达代理服务器，后面到底有多少源服务器，IP 都是多少，客户端是不知道的。因此，这个代理服务器可以拿到这个请求之后，可以通过特定的算法分发给不同的源服务器，让各台源服务器的负载尽量平均。当然，这样的算法有很多，包括**随机算法**、**轮询**、**一致性hash**、**LRU**`(最近最少使用)`等等，不过这些算法并不是本文的重点，大家有兴趣自己可以研究一下。
2. **保障安全**。利用**心跳**机制监控后台的服务器，一旦发现故障机就将其踢出集群。并且对于上下行的数据进行过滤，对非法 IP 限流，这些都是代理服务器的工作。
3. **缓存代理**。将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得而不用到源服务器那里。下一节详细拆解。

### 相关头部字段

#### Via

代理服务器需要标明自己的身份，在 HTTP 传输中留下自己的痕迹，怎么办呢？

通过`Via`字段来记录。举个例子，现在中间有两台代理服务器，在客户端发送请求后会经历这样一个过程:

```
客户端 -> 代理1 -> 代理2 -> 源服务器
复制代码
```

在源服务器收到请求后，会在`请求头`拿到这个字段:

```
Via: proxy_server1, proxy_server2
复制代码
```

而源服务器响应时，最终在客户端会拿到这样的`响应头`:

```
Via: proxy_server2, proxy_server1
复制代码
```

可以看到，`Via`中代理的顺序即为在 HTTP 传输中报文传达的顺序。

#### X-Forwarded-For

字面意思就是`为谁转发`, 它记录的是**请求方**的`IP`地址(注意，和`Via`区分开，`X-Forwarded-For`记录的是请求方这一个IP)。

#### X-Real-IP

是一种获取用户真实 IP 的字段，不管中间经过多少代理，这个字段始终记录最初的客户端的IP。

相应的，还有`X-Forwarded-Host`和`X-Forwarded-Proto`，分别记录**客户端**(注意哦，不包括代理)的`域名`和`协议名`。

### X-Forwarded-For产生的问题

前面可以看到，`X-Forwarded-For`这个字段记录的是请求方的 IP，这意味着每经过一个不同的代理，这个字段的名字都要变，从`客户端`到`代理1`，这个字段是客户端的 IP，从`代理1`到`代理2`，这个字段就变为了代理1的 IP。

但是这会产生两个问题:

1. 意味着代理必须解析 HTTP 请求头，然后修改，比直接转发数据性能下降。
2. 在 HTTPS 通信加密的过程中，原始报文是不允许修改的。

由此产生了`代理协议`，一般使用明文版本，只需要在 HTTP 请求行上面加上这样格式的文本即可:

```
// PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
PROXY TCP4 0.0.0.1 0.0.0.2 1111 2222
GET / HTTP/1.1
...
复制代码
```

这样就可以解决`X-Forwarded-For`带来的问题了。

## 013: 如何理解 HTTP 缓存及缓存代理？

关于`强缓存`和`协商缓存`的内容，我已经在[能不能说一说浏览器缓存](https://link.juejin.cn?target=http%3A%2F%2F47.98.159.95%2Fmy_blog%2Fperform%2F001.html)做了详细分析，小结如下:

首先通过 `Cache-Control` 验证强缓存是否可用

- 如果强缓存可用，直接使用

- 否则进入协商缓存，即发送 HTTP 请求，服务器通过请求头中的

  ```
  If-Modified-Since
  ```

  或者

  ```
  If-None-Match
  ```

  这些

  条件请求

  字段检查资源是否更新

  - 若资源更新，返回资源和200状态码
  - 否则，返回304，告诉浏览器直接从缓存获取资源

这一节我们主要来说说另外一种缓存方式: **代理缓存**。

### 为什么产生代理缓存？

对于源服务器来说，它也是有缓存的，比如**Redis, Memcache**，但对于 HTTP 缓存来说，如果每次客户端缓存失效都要到源服务器获取，那给源服务器的压力是很大的。

由此引入了**缓存代理**的机制。让`代理服务器`接管一部分的服务端HTTP缓存，客户端缓存过期后**就近**到代理缓存中获取，代理缓存过期了才请求源服务器，这样流量巨大的时候能明显降低源服务器的压力。

那缓存代理究竟是如何做到的呢？

总的来说，缓存代理的控制分为两部分，一部分是**源服务器**端的控制，一部分是**客户端**的控制。

### 源服务器的缓存控制

#### private 和 public

在源服务器的响应头中，会加上`Cache-Control`这个字段进行缓存控制字段，那么它的值当中可以加入`private`或者`public`表示是否允许代理服务器缓存，前者禁止，后者为允许。

比如对于一些非常私密的数据，如果缓存到代理服务器，别人直接访问代理就可以拿到这些数据，是非常危险的，因此对于这些数据一般是不会允许代理服务器进行缓存的，将响应头部的`Cache-Control`设为`private`，而不是`public`。

#### proxy-revalidate

`must-revalidate`的意思是**客户端**缓存过期就去源服务器获取，而`proxy-revalidate`则表示**代理服务器**的缓存过期后到源服务器获取。

#### s-maxage

`s`是`share`的意思，限定了缓存在代理服务器中可以存放多久，和限制客户端缓存时间的`max-age`并不冲突。

讲了这几个字段，我们不妨来举个小例子，源服务器在响应头中加入这样一个字段:

```
Cache-Control: public, max-age=1000, s-maxage=2000
复制代码
```

相当于源服务器说: 我这个响应是允许代理服务器缓存的，客户端缓存过期了到代理中拿，并且在客户端的缓存时间为 1000 秒，在代理服务器中的缓存时间为 2000 s。

### 客户端的缓存控制

#### max-stale 和 min-fresh

在客户端的请求头中，可以加入这两个字段，来对代理服务器上的缓存进行**宽容**和**限制**操作。比如：

```
max-stale: 5
复制代码
```

表示客户端到代理服务器上拿缓存的时候，即使代理缓存过期了也不要紧，只要过期时间在**5秒之内**，还是可以从代理中获取的。

又比如:

```
min-fresh: 5
复制代码
```

表示代理缓存需要一定的新鲜度，不要等到缓存刚好到期再拿，一定要在**到期前 5 秒**之前的时间拿，否则拿不到。

#### only-if-cached

这个字段加上后表示客户端只会接受代理缓存，而不会接受源服务器的响应。如果代理缓存无效，则直接返回`504（Gateway Timeout）`。

以上便是缓存代理的内容，涉及的字段比较多，希望能好好回顾一下，加深理解。

## 014: 什么是跨域？浏览器如何拦截响应？如何解决？

在前后端分离的开发模式中，经常会遇到跨域问题，即 Ajax 请求发出去了，服务器也成功响应了，前端就是拿不到这个响应。接下来我们就来好好讨论一下这个问题。

### 什么是跨域

回顾一下 URI 的组成:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd7ac23846fe~tplv-t2oaga2asx-watermark.awebp)



浏览器遵循**同源政策**(`scheme(协议)`、`host(主机)`和`port(端口)`都相同则为`同源`)。非同源站点有这样一些限制:

- 不能读取和修改对方的 DOM
- 不读访问对方的 Cookie、IndexDB 和 LocalStorage
- 限制 XMLHttpRequest 请求。(后面的话题着重围绕这个)

当浏览器向目标 URI 发 Ajax 请求时，只要当前 URL 和目标 URL 不同源，则产生跨域，被称为`跨域请求`。

跨域请求的响应一般会被浏览器所拦截，注意，是被浏览器拦截，响应其实是成功到达客户端了。那这个拦截是如何发生呢？

首先要知道的是，浏览器是多进程的，以 Chrome 为例，进程组成如下：



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd8131a4628f~tplv-t2oaga2asx-watermark.awebp)



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd83a20647db~tplv-t2oaga2asx-watermark.awebp)

**WebKit 渲染引擎**和**V8 引擎**都在渲染进程当中。

当`xhr.send`被调用，即 Ajax 请求准备发送的时候，其实还只是在渲染进程的处理。为了防止黑客通过脚本触碰到系统资源，浏览器将每一个渲染进程装进了沙箱，并且为了防止 CPU 芯片一直存在的**Spectre** 和 **Meltdown**漏洞，采取了`站点隔离`的手段，给每一个不同的站点(一级域名不同)分配了沙箱，互不干扰。具体见[YouTube上Chromium安全团队的演讲视频](https://link.juejin.cn?target=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DdBuykrdhK-A%26feature%3Demb_logo)。

在沙箱当中的渲染进程是没有办法发送网络请求的，那怎么办？只能通过网络进程来发送。那这样就涉及到进程间通信(IPC，Inter Process Communication)了。接下来我们看看 chromium 当中进程间通信是如何完成的，在 chromium 源码中调用顺序如下:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd924eaecb41~tplv-t2oaga2asx-watermark.awebp)



可能看了你会比较懵，如果想深入了解可以去看看 chromium 最新的源代码，[IPC源码地址](https://link.juejin.cn?target=https%3A%2F%2Fchromium.googlesource.com%2Fchromium%2Fsrc%2F%2B%2Frefs%2Fheads%2Fmaster%2Fipc%2F)及[Chromium IPC源码解析文章](https://link.juejin.cn?target=https%3A%2F%2Fblog.csdn.net%2FLuoshengyang%2Farticle%2Fdetails%2F47822689)。

总的来说就是利用`Unix Domain Socket`套接字，配合事件驱动的高性能网络并发库`libevent`完成进程的 IPC 过程。

好，现在数据传递给了浏览器主进程，主进程接收到后，才真正地发出相应的网络请求。

在服务端处理完数据后，将响应返回，主进程检查到跨域，且没有cors(后面会详细说)响应头，将响应体全部丢掉，并不会发送给渲染进程。这就达到了拦截数据的目的。

接下来我们来说一说解决跨域问题的几种方案。

### CORS

CORS 其实是 W3C 的一个标准，全称是`跨域资源共享`。它需要浏览器和服务器的共同支持，具体来说，非 IE 和 IE10 以上支持CORS，服务器需要附加特定的响应头，后面具体拆解。不过在弄清楚 CORS 的原理之前，我们需要清楚两个概念: **简单请求**和**非简单请求**。

浏览器根据请求方法和请求头的特定字段，将请求做了一下分类，具体来说规则是这样，凡是满足下面条件的属于**简单请求**:

- 请求方法为 GET、POST 或者 HEAD
- 请求头的取值范围: Accept、Accept-Language、Content-Language、Content-Type(只限于三个值`application/x-www-form-urlencoded`、`multipart/form-data`、`text/plain`)

浏览器画了这样一个圈，在这个圈里面的就是**简单请求**, 圈外面的就是**非简单请求**，然后针对这两种不同的请求进行不同的处理。

#### 简单请求

请求发出去之前，浏览器做了什么？

它会自动在请求头当中，添加一个`Origin`字段，用来说明请求来自哪个`源`。服务器拿到请求之后，在回应时对应地添加`Access-Control-Allow-Origin`字段，如果`Origin`不在这个字段的范围中，那么浏览器就会将响应拦截。

因此，`Access-Control-Allow-Origin`字段是服务器用来决定浏览器是否拦截这个响应，这是必需的字段。与此同时，其它一些可选的功能性的字段，用来描述如果不会拦截，这些字段将会发挥各自的作用。

**Access-Control-Allow-Credentials**。这个字段是一个布尔值，表示是否允许发送 Cookie，对于跨域请求，浏览器对这个字段默认值设为 false，而如果需要拿到浏览器的 Cookie，需要添加这个响应头并设为`true`, 并且在前端也需要设置`withCredentials`属性:

```
let xhr = new XMLHttpRequest();
xhr.withCredentials = true;
复制代码
```

**Access-Control-Expose-Headers**。这个字段是给 XMLHttpRequest 对象赋能，让它不仅可以拿到基本的 6 个响应头字段（包括`Cache-Control`、`Content-Language`、`Content-Type`、`Expires`、`Last-Modified`和`Pragma`）, 还能拿到这个字段声明的**响应头字段**。比如这样设置:

```
Access-Control-Expose-Headers: aaa
复制代码
```

那么在前端可以通过 `XMLHttpRequest.getResponseHeader('aaa')` 拿到 `aaa` 这个字段的值。

#### 非简单请求

非简单请求相对而言会有些不同，体现在两个方面: **预检请求**和**响应字段**。

我们以 PUT 方法为例。

```
var url = 'http://xxx.com';
var xhr = new XMLHttpRequest();
xhr.open('PUT', url, true);
xhr.setRequestHeader('X-Custom-Header', 'xxx');
xhr.send();
复制代码
```

当这段代码执行后，首先会发送**预检请求**。这个预检请求的请求行和请求体是下面这个格式:

```
OPTIONS / HTTP/1.1
Origin: 当前地址
Host: xxx.com
Access-Control-Request-Method: PUT
Access-Control-Request-Headers: X-Custom-Header
复制代码
```

预检请求的方法是`OPTIONS`，同时会加上`Origin`源地址和`Host`目标地址，这很简单。同时也会加上两个关键的字段:

- Access-Control-Request-Method, 列出 CORS 请求用到哪个HTTP方法
- Access-Control-Request-Headers，指定 CORS 请求将要加上什么请求头

这是`预检请求`。接下来是**响应字段**，响应字段也分为两部分，一部分是对于**预检请求**的响应，一部分是对于 **CORS 请求**的响应。

**预检请求的响应**。如下面的格式:

```
HTTP/1.1 200 OK
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET, POST, PUT
Access-Control-Allow-Headers: X-Custom-Header
Access-Control-Allow-Credentials: true
Access-Control-Max-Age: 1728000
Content-Type: text/html; charset=utf-8
Content-Encoding: gzip
Content-Length: 0
复制代码
```

其中有这样几个关键的**响应头字段**:

- Access-Control-Allow-Origin: 表示可以允许请求的源，可以填具体的源名，也可以填`*`表示允许任意源请求。
- Access-Control-Allow-Methods: 表示允许的请求方法列表。
- Access-Control-Allow-Credentials: 简单请求中已经介绍。
- Access-Control-Allow-Headers: 表示允许发送的请求头字段
- Access-Control-Max-Age: 预检请求的有效期，在此期间，不用发出另外一条预检请求。

在预检请求的响应返回后，如果请求不满足响应头的条件，则触发`XMLHttpRequest`的`onerror`方法，当然后面真正的**CORS请求**也不会发出去了。

**CORS 请求的响应**。绕了这么一大转，到了真正的 CORS 请求就容易多了，现在它和**简单请求**的情况是一样的。浏览器自动加上`Origin`字段，服务端响应头返回**Access-Control-Allow-Origin**。可以参考以上简单请求部分的内容。

### JSONP

虽然`XMLHttpRequest`对象遵循同源政策，但是`script`标签不一样，它可以通过 src 填上目标地址从而发出 GET 请求，实现跨域请求并拿到响应。这也就是 JSONP 的原理，接下来我们就来封装一个 JSONP:

```
const jsonp = ({ url, params, callbackName }) => {
  const generateURL = () => {
    let dataStr = '';
    for(let key in params) {
      dataStr += `${key}=${params[key]}&`;
    }
    dataStr += `callback=${callbackName}`;
    return `${url}?${dataStr}`;
  };
  return new Promise((resolve, reject) => {
    // 初始化回调函数名称
    callbackName = callbackName || Math.random().toString.replace(',', ''); 
    // 创建 script 元素并加入到当前文档中
    let scriptEle = document.createElement('script');
    scriptEle.src = generateURL();
    document.body.appendChild(scriptEle);
    // 绑定到 window 上，为了后面调用
    window[callbackName] = (data) => {
      resolve(data);
      // script 执行完了，成为无用元素，需要清除
      document.body.removeChild(scriptEle);
    }
  });
}
复制代码
```

当然在服务端也会有响应的操作, 以 express 为例:

```
let express = require('express')
let app = express()
app.get('/', function(req, res) {
  let { a, b, callback } = req.query
  console.log(a); // 1
  console.log(b); // 2
  // 注意哦，返回给script标签，浏览器直接把这部分字符串执行
  res.end(`${callback}('数据包')`);
})
app.listen(3000)
复制代码
```

前端这样简单地调用一下就好了:

```
jsonp({
  url: 'http://localhost:3000',
  params: { 
    a: 1,
    b: 2
  }
}).then(data => {
  // 拿到数据进行处理
  console.log(data); // 数据包
})
复制代码
```

和`CORS`相比，JSONP 最大的优势在于兼容性好，IE 低版本不能使用 CORS 但可以使用 JSONP，缺点也很明显，请求方法单一，只支持 GET 请求。

### Nginx

Nginx 是一种高性能的`反向代理`服务器，可以用来轻松解决跨域问题。

what？反向代理？我给你看一张图你就懂了。



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd97d0b1cf15~tplv-t2oaga2asx-watermark.awebp)



正向代理帮助客户端**访问**客户端自己访问不到的服务器，然后将结果返回给客户端。

反向代理拿到客户端的请求，将请求转发给其他的服务器，主要的场景是维持服务器集群的**负载均衡**，换句话说，反向代理帮**其它的服务器**拿到请求，然后选择一个合适的服务器，将请求转交给它。

因此，两者的区别就很明显了，正向代理服务器是帮**客户端**做事情，而反向代理服务器是帮其它的**服务器**做事情。

好了，那 Nginx 是如何来解决跨域的呢？

比如说现在客户端的域名为**client.com**，服务器的域名为**server.com**，客户端向服务器发送 Ajax 请求，当然会跨域了，那这个时候让 Nginx 登场了，通过下面这个配置:

```
server {
  listen  80;
  server_name  client.com;
  location /api {
    proxy_pass server.com;
  }
}
复制代码
```

Nginx 相当于起了一个跳板机，这个跳板机的域名也是`client.com`，让客户端首先访问 `client.com/api`，这当然没有跨域，然后 Nginx 服务器作为反向代理，将请求转发给`server.com`，当响应返回时又将响应给到客户端，这就完成整个跨域请求的过程。

其实还有一些不太常用的方式，大家了解即可，比如`postMessage`，当然`WebSocket`也是一种方式，但是已经不属于 HTTP 的范畴，另外一些奇技淫巧就不建议大家去死记硬背了，一方面从来不用，名字都难得记住，另一方面临时背下来，面试官也不会对你印象加分，因为看得出来是背的。当然没有背并不代表减分，把跨域原理和前面三种主要的跨域方式理解清楚，经得起更深一步的推敲，反而会让别人觉得你是一个靠谱的人。

## 015: TLS1.2 握手的过程是怎样的？

之前谈到了 HTTP 是明文传输的协议，传输保文对外完全透明，非常不安全，那如何进一步保证安全性呢？

由此产生了 `HTTPS`，其实它并不是一个新的协议，而是在 HTTP 下面增加了一层 SSL/TLS 协议，简单的讲，**HTTPS = HTTP + SSL/TLS**。

那什么是 SSL/TLS 呢？

SSL 即安全套接层（Secure Sockets Layer），在 OSI 七层模型中处于会话层(第 5 层)。之前 SSL 出过三个大版本，当它发展到第三个大版本的时候才被标准化，成为 TLS（传输层安全，Transport Layer Security），并被当做 TLS1.0 的版本，准确地说，**TLS1.0 = SSL3.1**。

现在主流的版本是 TLS/1.2, 之前的 TLS1.0、TLS1.1 都被认为是不安全的，在不久的将来会被完全淘汰。因此我们接下来主要讨论的是 TLS1.2, 当然在 2018 年推出了更加优秀的 TLS1.3，大大优化了 TLS 握手过程，这个我们放在下一节再去说。

TLS 握手的过程比较复杂，写文章之前我查阅了大量的资料，发现对 TLS 初学者非常不友好，也有很多知识点说的含糊不清，可以说这个整理的过程是相当痛苦了。希望我下面的拆解能够帮你理解得更顺畅些吧 : ）

### 传统 RSA 握手

先来说说传统的 TLS 握手，也是大家在网上经常看到的。我之前也写过这样的文章，[(传统RSA版本)HTTPS为什么让数据传输更安全](https://link.juejin.cn?target=http%3A%2F%2F47.98.159.95%2Fmy_blog%2Fbrowser-security%2F003.html)，其中也介绍到了`对称加密`和`非对称加密`的概念，建议大家去读一读，不再赘述。之所以称它为 RSA 版本，是因为它在加解密`pre_random`的时候采用的是 RSA 算法。

### TLS 1.2 握手过程

现在我们来讲讲主流的 TLS 1.2 版本所采用的方式。



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffd9b35c7a81b~tplv-t2oaga2asx-watermark.awebp)



刚开始你可能会比较懵，先别着急，过一遍下面的流程再来看会豁然开朗。

#### step 1: Client Hello

首先，浏览器发送 client_random、TLS版本、加密套件列表。

client_random 是什么？用来最终 secret 的一个参数。

加密套件列表是什么？我举个例子，加密套件列表一般张这样:

```
TLS_ECDHE_WITH_AES_128_GCM_SHA256
复制代码
```

意思是`TLS`握手过程中，使用`ECDHE`算法生成`pre_random`(这个数后面会介绍)，128位的`AES`算法进行对称加密，在对称加密的过程中使用主流的`GCM`分组模式，因为对称加密中很重要的一个问题就是如何分组。最后一个是哈希摘要算法，采用`SHA256`算法。

其中值得解释一下的是这个哈希摘要算法，试想一个这样的场景，服务端现在给客户端发消息来了，客户端并不知道此时的消息到底是服务端发的，还是中间人伪造的消息呢？现在引入这个哈希摘要算法，将服务端的证书信息通过**这个算法**生成一个摘要(可以理解为`比较短的字符串`)，用来**标识**这个服务端的身份，用私钥加密后把**加密后的标识**和**自己的公钥**传给客户端。客户端拿到**这个公钥**来解密，生成另外一份摘要。两个摘要进行对比，如果相同则能确认服务端的身份。这也就是所谓**数字签名**的原理。其中除了哈希算法，最重要的过程是**私钥加密，公钥解密**。

#### step 2: Server Hello

可以看到服务器一口气给客户端回复了非常多的内容。

`server_random`也是最后生成`secret`的一个参数, 同时确认 TLS 版本、需要使用的加密套件和自己的证书，这都不难理解。那剩下的`server_params`是干嘛的呢？

我们先埋个伏笔，现在你只需要知道，`server_random`到达了客户端。

#### step 3: Client 验证证书，生成secret

客户端验证服务端传来的`证书`和`签名`是否通过，如果验证通过，则传递`client_params`这个参数给服务器。

接着客户端通过`ECDHE`算法计算出`pre_random`，其中传入两个参数:**server_params**和**client_params**。现在你应该清楚这个两个参数的作用了吧，由于`ECDHE`基于`椭圆曲线离散对数`，这两个参数也称作`椭圆曲线的公钥`。

客户端现在拥有了`client_random`、`server_random`和`pre_random`，接下来将这三个数通过一个伪随机数函数来计算出最终的`secret`。

#### step4: Server 生成 secret

刚刚客户端不是传了`client_params`过来了吗？

现在服务端开始用`ECDHE`算法生成`pre_random`，接着用和客户端同样的伪随机数函数生成最后的`secret`。

#### 注意事项

TLS的过程基本上讲完了，但还有两点需要注意。

**第一**、实际上 TLS 握手是一个**双向认证**的过程，从 step1 中可以看到，客户端有能力验证服务器的身份，那服务器能不能验证客户端的身份呢？

当然是可以的。具体来说，在 `step3`中，客户端传送`client_params`，实际上给服务器传一个验证消息，让服务器将相同的验证流程(哈希摘要 + 私钥加密 + 公钥解密)走一遍，确认客户端的身份。

**第二**、当客户端生成`secret`后，会给服务端发送一个收尾的消息，告诉服务器之后的都用对称加密，对称加密的算法就用第一次约定的。服务器生成完`secret`也会向客户端发送一个收尾的消息，告诉客户端以后就直接用对称加密来通信。

这个收尾的消息包括两部分，一部分是`Change Cipher Spec`，意味着后面加密传输了，另一个是`Finished`消息，这个消息是对之前所有发送的数据做的**摘要**，对摘要进行加密，让对方验证一下。

当双方都验证通过之后，握手才正式结束。后面的 HTTP 正式开始传输加密报文。

#### RSA 和 ECDHE 握手过程的区别

1. ECDHE 握手，也就是主流的 TLS1.2 握手中，使用`ECDHE`实现`pre_random`的加密解密，没有用到 RSA。
2. 使用 ECDHE 还有一个特点，就是客户端发送完收尾消息后可以提前`抢跑`，直接发送 HTTP 报文，节省了一个 RTT，不必等到收尾消息到达服务器，然后等服务器返回收尾消息给自己，直接开始发请求。这也叫`TLS False Start`。

## 016: TLS 1.3 做了哪些改进？

TLS 1.2 虽然存在了 10 多年，经历了无数的考验，但历史的车轮总是不断向前的，为了获得更强的安全、更优秀的性能，在`2018年`就推出了 TLS1.3，对于`TLS1.2`做了一系列的改进，主要分为这几个部分:**强化安全**、**提高性能**。

### 强化安全

在 TLS1.3 中废除了非常多的加密算法，最后只保留五个加密套件:

- TLS_AES_128_GCM_SHA256
- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_GCM_8_SHA256

可以看到，最后剩下的对称加密算法只有 **AES** 和 **CHACHA20**，之前主流的也会这两种。分组模式也只剩下 **GCM** 和 **POLY1305**, 哈希摘要算法只剩下了 **SHA256** 和 **SHA384** 了。

那你可能会问了, 之前`RSA`这么重要的非对称加密算法怎么不在了？

我觉得有两方面的原因:

**第一**、2015年发现了`FREAK`攻击，即已经有人发现了 RSA 的漏洞，能够进行破解了。

**第二**、一旦私钥泄露，那么中间人可以通过私钥计算出之前所有报文的`secret`，破解之前所有的密文。

为什么？回到 RSA 握手的过程中，客户端拿到服务器的证书后，提取出服务器的公钥，然后生成`pre_random`并用**公钥**加密传给服务器，服务器通过**私钥**解密，从而拿到真实的`pre_random`。当中间人拿到了服务器私钥，并且截获之前所有报文的时候，那么就能拿到`pre_random`、`server_random`和`client_random`并根据对应的随机数函数生成`secret`，也就是拿到了 TLS 最终的会话密钥，每一个历史报文都能通过这样的方式进行破解。

但`ECDHE`在每次握手时都会生成临时的密钥对，即使私钥被破解，之前的历史消息并不会收到影响。这种一次破解并不影响历史信息的性质也叫**前向安全性**。

`RSA` 算法不具备前向安全性，而 `ECDHE` 具备，因此在 TLS1.3 中彻底取代了`RSA`。

### 提升性能

#### 握手改进

流程如下:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffda75857d404~tplv-t2oaga2asx-watermark.awebp)



大体的方式和 TLS1.2 差不多，不过和 TLS 1.2 相比少了一个 RTT， 服务端不必等待对方验证证书之后才拿到`client_params`，而是直接在第一次握手的时候就能够拿到, 拿到之后立即计算`secret`，节省了之前不必要的等待时间。同时，这也意味着在第一次握手的时候客户端需要传送更多的信息，一口气给传完。

这种 TLS 1.3 握手方式也被叫做**1-RTT握手**。但其实这种`1-RTT`的握手方式还是有一些优化的空间的，接下来我们来一一介绍这些优化方式。

#### 会话复用

会话复用有两种方式: **Session ID**和**Session Ticket**。

先说说最早出现的**Seesion ID**，具体做法是客户端和服务器首次连接后各自保存会话的 ID，并存储会话密钥，当再次连接时，客户端发送`ID`过来，服务器查找这个 ID 是否存在，如果找到了就直接复用之前的会话状态，会话密钥不用重新生成，直接用原来的那份。

但这种方式也存在一个弊端，就是当客户端数量庞大的时候，对服务端的存储压力非常大。

因而出现了第二种方式——**Session Ticket**。它的思路就是: 服务端的压力大，那就把压力分摊给客户端呗。具体来说，双方连接成功后，服务器加密会话信息，用**Session Ticket**消息发给客户端，让客户端保存下来。下次重连的时候，就把这个 Ticket 进行解密，验证它过没过期，如果没过期那就直接恢复之前的会话状态。

这种方式虽然减小了服务端的存储压力，但与带来了安全问题，即每次用一个固定的密钥来解密 Ticket 数据，一旦黑客拿到这个密钥，之前所有的历史记录也被破解了。因此为了尽量避免这样的问题，密钥需要定期进行更换。

总的来说，这些会话复用的技术在保证`1-RTT`的同时，也节省了生成会话密钥这些算法所消耗的时间，是一笔可观的性能提升。

#### PSK

刚刚说的都是`1-RTT`情况下的优化，那能不能优化到`0-RTT`呢？

答案是可以的。做法其实也很简单，在发送**Session Ticket**的同时带上应用数据，不用等到服务端确认，这种方式被称为`Pre-Shared Key`，即 PSK。

这种方式虽然方便，但也带来了安全问题。中间人截获`PSK`的数据，不断向服务器重复发，类似于 TCP 第一次握手携带数据，增加了服务器被攻击的风险。

### 总结

TLS1.3 在 TLS1.2 的基础上废除了大量的算法，提升了安全性。同时利用会话复用节省了重新生成密钥的时间，利用 PSK 做到了`0-RTT`连接。

## 017: HTTP/2 有哪些改进？

由于 HTTPS 在安全方面已经做的非常好了，HTTP 改进的关注点放在了性能方面。对于 HTTP/2 而言，它对于性能的提升主要在于两点:

- 头部压缩
- 多路复用

当然还有一些颠覆性的功能实现:

- 设置请求优先级
- 服务器推送

这些重大的提升本质上也是为了解决 HTTP 本身的问题而产生的。接下来我们来看看 HTTP/2 解决了哪些问题，以及解决方式具体是如何的。

### 头部压缩

在 HTTP/1.1 及之前的时代，**请求体**一般会有响应的压缩编码过程，通过`Content-Encoding`头部字段来指定，但你有没有想过头部字段本身的压缩呢？当请求字段非常复杂的时候，尤其对于 GET 请求，请求报文几乎全是请求头，这个时候还是存在非常大的优化空间的。HTTP/2 针对头部字段，也采用了对应的压缩算法——HPACK，对请求头进行压缩。

HPACK 算法是专门为 HTTP/2 服务的，它主要的亮点有两个：

- 首先是在服务器和客户端之间建立哈希表，将用到的字段存放在这张表中，那么在传输的时候对于之前出现过的值，只需要把**索引**(比如0，1，2，...)传给对方即可，对方拿到索引查表就行了。这种**传索引**的方式，可以说让请求头字段得到极大程度的精简和复用。



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffdaa6f41c004~tplv-t2oaga2asx-watermark.awebp)



> HTTP/2 当中废除了起始行的概念，将起始行中的请求方法、URI、状态码转换成了头字段，不过这些字段都有一个":"前缀，用来和其它请求头区分开。

- 其次是对于整数和字符串进行**哈夫曼编码**，哈夫曼编码的原理就是先将所有出现的字符建立一张索引表，然后让出现次数多的字符对应的索引尽可能短，传输的时候也是传输这样的**索引序列**，可以达到非常高的压缩率。

### 多路复用

#### HTTP 队头阻塞

我们之前讨论了 HTTP 队头阻塞的问题，其根本原因在于HTTP 基于`请求-响应`的模型，在同一个 TCP 长连接中，前面的请求没有得到响应，后面的请求就会被阻塞。

后面我们又讨论到用**并发连接**和**域名分片**的方式来解决这个问题，但这并没有真正从 HTTP 本身的层面解决问题，只是增加了 TCP 连接，分摊风险而已。而且这么做也有弊端，多条 TCP 连接会竞争**有限的带宽**，让真正优先级高的请求不能优先处理。

而 HTTP/2 便从 HTTP 协议本身解决了`队头阻塞`问题。注意，这里并不是指的`TCP队头阻塞`，而是`HTTP队头阻塞`，两者并不是一回事。TCP 的队头阻塞是在`数据包`层面，单位是`数据包`，前一个报文没有收到便不会将后面收到的报文上传给 HTTP，而HTTP 的队头阻塞是在 `HTTP 请求-响应`层面，前一个请求没处理完，后面的请求就要阻塞住。两者所在的层次不一样。

那么 HTTP/2 如何来解决所谓的队头阻塞呢？

#### 二进制分帧

首先，HTTP/2 认为明文传输对机器而言太麻烦了，不方便计算机的解析，因为对于文本而言会有多义性的字符，比如回车换行到底是内容还是分隔符，在内部需要用到状态机去识别，效率比较低。于是 HTTP/2 干脆把报文全部换成二进制格式，全部传输`01`串，方便了机器的解析。

原来`Headers + Body`的报文格式如今被拆分成了一个个二进制的帧，用**Headers帧**存放头部字段，**Data帧**存放请求体数据。分帧之后，服务器看到的不再是一个个完整的 HTTP 请求报文，而是一堆乱序的二进制帧。这些二进制帧不存在先后关系，因此也就不会排队等待，也就没有了 HTTP 的队头阻塞问题。

通信双方都可以给对方发送二进制帧，这种二进制帧的**双向传输的序列**，也叫做`流`(Stream)。HTTP/2 用`流`来在一个 TCP 连接上来进行多个数据帧的通信，这就是**多路复用**的概念。

可能你会有一个疑问，既然是乱序首发，那最后如何来处理这些乱序的数据帧呢？

首先要声明的是，所谓的乱序，指的是不同 ID 的 Stream 是乱序的，但同一个 Stream ID 的帧一定是按顺序传输的。二进制帧到达后对方会将 Stream ID 相同的二进制帧组装成完整的**请求报文**和**响应报文**。当然，在二进制帧当中还有其他的一些字段，实现了**优先级**和**流量控制**等功能，我们放到下一节再来介绍。

### 服务器推送

另外值得一说的是 HTTP/2 的服务器推送(Server Push)。在 HTTP/2 当中，服务器已经不再是完全被动地接收请求，响应请求，它也能新建 stream 来给客户端发送消息，当 TCP 连接建立之后，比如浏览器请求一个 HTML 文件，服务器就可以在返回 HTML 的基础上，将 HTML 中引用到的其他资源文件一起返回给客户端，减少客户端的等待。

### 总结

当然，HTTP/2 新增那么多的特性，是不是 HTTP 的语法要重新学呢？不需要，HTTP/2 完全兼容之前 HTTP 的语法和语义，如**请求头、URI、状态码、头部字段**都没有改变，完全不用担心。同时，在安全方面，HTTP 也支持 TLS，并且现在主流的浏览器都公开只支持加密的 HTTP/2, 因此你现在能看到的 HTTP/2 也基本上都是跑在 TLS 上面的了。最后放一张分层图给大家参考:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffdc6783132a5~tplv-t2oaga2asx-watermark.awebp)



## 018: HTTP/2 中的二进制帧是如何设计的？

### 帧结构

HTTP/2 中传输的帧结构如下图所示:



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffdc9e9c25e93~tplv-t2oaga2asx-watermark.awebp)



每个帧分为`帧头`和`帧体`。先是三个字节的帧长度，这个长度表示的是`帧体`的长度。

然后是帧类型，大概可以分为**数据帧**和**控制帧**两种。数据帧用来存放 HTTP 报文，控制帧用来管理`流`的传输。

接下来的一个字节是**帧标志**，里面一共有 8 个标志位，常用的有 **END_HEADERS**表示头数据结束，**END_STREAM**表示单方向数据发送结束。

后 4 个字节是`Stream ID`, 也就是`流标识符`，有了它，接收方就能从乱序的二进制帧中选择出 ID 相同的帧，按顺序组装成请求/响应报文。

### 流的状态变化

从前面可以知道，在 HTTP/2 中，所谓的`流`，其实就是二进制帧的**双向传输的序列**。那么在 HTTP/2 请求和响应的过程中，流的状态是如何变化的呢？

HTTP/2 其实也是借鉴了 TCP 状态变化的思想，根据帧的标志位来实现具体的状态改变。这里我们以一个普通的`请求-响应`过程为例来说明：



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/3/22/170ffdcd0abdd1ba~tplv-t2oaga2asx-watermark.awebp)



最开始两者都是空闲状态，当客户端发送`Headers帧`后，开始分配`Stream ID`, 此时客户端的`流`打开, 服务端接收之后服务端的`流`也打开，两端的`流`都打开之后，就可以互相传递数据帧和控制帧了。

当客户端要关闭时，向服务端发送`END_STREAM`帧，进入`半关闭状态`, 这个时候客户端只能接收数据，而不能发送数据。

服务端收到这个`END_STREAM`帧后也进入`半关闭状态`，不过此时服务端的情况是只能发送数据，而不能接收数据。随后服务端也向客户端发送`END_STREAM`帧，表示数据发送完毕，双方进入`关闭状态`。

如果下次要开启新的`流`，流 ID 需要自增，直到上限为止，到达上限后开一个新的 TCP 连接重头开始计数。由于流 ID 字段长度为 4 个字节，最高位又被保留，因此范围是 0 ~ 2的 31 次方，大约 21 亿个。

### 流的特性

刚刚谈到了流的状态变化过程，这里顺便就来总结一下`流`传输的特性:

- 并发性。一个 HTTP/2 连接上可以同时发多个帧，这一点和 HTTP/1 不同。这也是实现**多路**复用的基础。
- 自增性。流 ID 是不可重用的，而是会按顺序递增，达到上限之后又新开 TCP 连接从头开始。
- 双向性。客户端和服务端都可以创建流，互不干扰，双方都可以作为`发送方`或者`接收方`。
- 可设置优先级。可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。

以上就是对 HTTP/2 中二进制帧的介绍，希望对你有所启发。

